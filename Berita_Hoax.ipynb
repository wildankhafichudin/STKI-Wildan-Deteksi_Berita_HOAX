{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Pre-Processing \"Mendeteksi Berita Hoax\" #\n",
        "\n",
        "Text Pre-processing merupakan langkah menyiapkan data teks untuk bisa dimodelkan ke dalam machine learning. Secara umum tahapan text pre-processing bisa dikategorikan menjadi:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Tahapan Wajib, tahapan yang pasti dilakukan setiap melakukan text pre-processing. Tahapan ini adalah Tokenisasi\n",
        "2.   Tahapan Umum, tahapan ini yang sering sekali dilakukan oleh praktisi. Tahapan ini tidak wajib dilakukan dan sangat bergantung pada tujuan analisis yang ingin dilakukan. Beberapa tahapan yang masuk dalam kategori ini adalah:\n",
        "  - Case Folding (Capital/Non Capital letters)\n",
        "  - Menghilangkan Tanda Baca (punctuation removal)\n",
        "  Menghapus whitepace (Whitespace removal)\n",
        "  - Menghapus/mentransformasi angka\n",
        "  - Menghapus Stop Word (Stop Word Removal)\n",
        "  - Text Normalization/Noise Removal (seperti mengubah bahasa tidak baku menjadi baku,mengubah singkatan, menghapus karater khusus seperti @ dan #)\n",
        "  - Stemming/Lemmatization\n",
        "  - Tahapan Tambahan (Other Steps, tahapan ini tidak sering dilakukan oleh praktisi karena hanya digunakan pada kasus-kasus khusus)\n",
        "\n",
        "Language Detection (jika kumpulan teks mengandung lebih dari satu bahasa)\n",
        "Code Mixing/Transliteration (jika dalam satu teks mengandung lebih dari satu bahasa, misalnya bahasa gaul jaksel)\n",
        "\n",
        "\n",
        "# Resources Bahasa Indonesia untuk Text Pre-processing #\n",
        "Beberapa resources text pre-processing bahasa indonesia yang dapat digunakan:\n",
        "\n",
        "1. KirraLabs: Mix of NLP-TextMining resources\n",
        "2. Sastrawi 1.0.1: untuk \"stemming\" & stopwords bahasa Indonesia.\n",
        "3. Daftar Kata Dasar Indonesia: Bisa di load sebagai dictionary di Python\n",
        "4. Wiktionary: ProyekWiki bahasa Indonesia [termasuk Lexicon]\n",
        "5. WordNet Bahasa Indonesia: Bisa di load sebagai dictionary (atau NLTK*) di Python.\n",
        "6. Daftar Kata Baku-Tidak Baku: Bisa di load sebagai dictionary di Python.\n",
        "7. Spacy: Cepat/efisien, MIT License, tapi language model Indonesia masih terbatas.\n",
        "8. UdPipe: Online request & restricted license (support berbagai bahasa - pemrograman).\n",
        "9. Kamus Alay: Daftar bahasa gaul.\n",
        "10. Indonesia NLP Resources github: Resources di github.\n",
        "11. NLP Bahasa Indonesia Resources: Resources di github.\n",
        "\n",
        "Di python, ada beberapa package (modul) yang dapat membantu kita untuk menangani masalah teks ini, seperti:\n",
        "\n",
        "- Spacy\n",
        "- NLTK\n",
        "- Gensim\n",
        "- TextBlob\n",
        "- PySastrawi (Khusus Bahasa Indonesia)\n",
        "\n",
        "Dalam tutorial ini kita akan fokus menggunakan Spacy,NLTK dan PySastrawi. Selain package diatas, ada beberapa sumber lain yang dapat membantu kita untuk pengolahan teks ini seperti:\n",
        "\n",
        "1. Indonesian stopwords\n",
        "2. Daftar Kata Baku-Tidak Baku\n",
        "3. Kamus Alay"
      ],
      "metadata": {
        "id": "ZYZwRcOrKMH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ETsAma4nxN5C",
        "outputId": "c899ebc4-65de-4e98-bba6-4bc358cf5336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0               utk kamu yg disana, sdh makan belum?\n",
              "1  Bangkai 120 lumba-lumba ditemukan di sungai Am...\n",
              "2       Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
              "3  Galau bgt mau dukung Ji Chang Wook atau Wi Ha ...\n",
              "4  Kasus Covid-19 bertambah 40.618 pada Kamis (10..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9cfac26-3e98-4659-b6f1-e8f07a241682\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utk kamu yg disana, sdh makan belum?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bangkai 120 lumba-lumba ditemukan di sungai Am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gue ga suka makan bakso, jangan dipaksaaa!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Galau bgt mau dukung Ji Chang Wook atau Wi Ha ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kasus Covid-19 bertambah 40.618 pada Kamis (10...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9cfac26-3e98-4659-b6f1-e8f07a241682')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9cfac26-3e98-4659-b6f1-e8f07a241682 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9cfac26-3e98-4659-b6f1-e8f07a241682');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48e4d288-66a7-401d-90cc-a5bc9ba6494c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48e4d288-66a7-401d-90cc-a5bc9ba6494c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48e4d288-66a7-401d-90cc-a5bc9ba6494c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dummy_doc = pd.DataFrame({\"text\":[\"utk kamu yg disana, sdh makan belum?\",\n",
        "                                  \"Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\",\n",
        "                                  \"Gue ga suka makan bakso, jangan dipaksaaa!!!\",\n",
        "                                  \"Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\",\n",
        "                                  \"Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\"\n",
        "                                  ]})\n",
        "dummy_doc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in range(0,5):\n",
        "  print(dummy_doc.iloc[row,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm7mjtltyAP8",
        "outputId": "7dd70b9c-721e-4c81-fd5d-63d3a5095ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utk kamu yg disana, sdh makan belum?\n",
            "Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\n",
            "Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_text_in_df(doc):\n",
        "  for row in range(0,doc.shape[0]):\n",
        "    print(doc.iloc[row,0])"
      ],
      "metadata": {
        "id": "ZFWmubL9yEdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisasi #\n",
        "Tokenisasi merupakan tahap yang wajib dilakukan pada saat text pre-processing. Pada tahap ini, kita memisahkan teks menjadi unit-unit yang lebih kecil. Unit-unit ini disebut juga dengan token. Di sini, token dapat berupa kata, karakter, atau subkata. Oleh karena itu, tokenisasi secara luas dapat diklasifikasikan menjadi 3 jenis yaitu\n",
        "\n",
        "* tokenisasi (word) kata\n",
        "* tokenisasi karakter(character)\n",
        "* tokenisasi sub kata (karakter n-gram).\n",
        "\n",
        "Membuat Kosakata adalah tujuan akhir dari Tokenisasi.\n",
        "\n",
        "Misalkan saja, kalimat: Aku suka mangga.\n",
        "\n",
        "Cara paling umum untuk membentuk token didasarkan pada spasi. Dengan asumsi spasi sebagai pemisah, tokenisasi kata (word tokenization) Aku suka mangga menghasilkan 3 token yaitu Aku-suka-mangga. Karena setiap token adalah sebuah kata, itu menjadi contoh tokenisasi kata.\n",
        "\n",
        "Demikian pula, token dapat berupa karakter atau subkata. Misalnya, kata menghasilkan:\n",
        "\n",
        "* Token karakter: m-e-n-g-h-a-s-i-l-k-a-n\n",
        "* Token sub kata: meng-hasil-kan"
      ],
      "metadata": {
        "id": "OHiR6gHzNaLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisasi Kata dalam Python #"
      ],
      "metadata": {
        "id": "AC8-FnuON3YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_token_default(doc):\n",
        "  return doc.split()"
      ],
      "metadata": {
        "id": "_jrH1hqsyOll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_token_default(dummy_doc.iloc[3,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxw0yz21yS6F",
        "outputId": "6af1c54e-b1bd-4a6c-ca8a-f696b50dd4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Galau', 'bgt', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon...', 'Semuanya', 'kasian', 'huhu..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt!', '<3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc1 = dummy_doc.apply(lambda doc: word_token_default(doc.iloc[0]),axis=1)\n",
        "print(type(dummy_doc1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqA0oOkkycS_",
        "outputId": "ca2adde7-f592-4bb6-baba-49f29d3b1373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Menampilkan kata\n",
        "print_text_in_df(dummy_doc1.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuYBZCjxyhAB",
        "outputId": "9b636b62-3d94-4c28-d9db-bbd43a84dc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['utk', 'kamu', 'yg', 'disana,', 'sdh', 'makan', 'belum?']\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'di', 'sungai', 'Amazon', 'selama', 'seminggu', 'terakhir.']\n",
            "['Gue', 'ga', 'suka', 'makan', 'bakso,', 'jangan', 'dipaksaaa!!!']\n",
            "['Galau', 'bgt', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon...', 'Semuanya', 'kasian', 'huhu..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt!', '<3']\n",
            "['Kasus', 'Covid-19', 'bertambah', '40.618', 'pada', 'Kamis', '(10/2),', 'sehingga', 'total', 'kasus', 'mencapai', '4.667.554.', 'Sebanyak', '4.234.510', 'orang', 'telah', 'sembuh,', 'dan', '144.858', 'meninggal', 'dunia.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan Spacy #"
      ],
      "metadata": {
        "id": "IF06gLh9N92P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.id import Indonesian\n",
        "import spacy\n",
        "nlp = Indonesian()"
      ],
      "metadata": {
        "id": "l9O-z3inyjtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_token_spacy(doc):\n",
        "  doc1 = nlp(doc)\n",
        "  token = [token.text for token in doc1]\n",
        "  return token"
      ],
      "metadata": {
        "id": "7XDErSSqyon6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_token_spacy(dummy_doc.iloc[3,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s0dAF7_yrjO",
        "outputId": "c6680a77-108d-48c2-921b-3d74a8dda434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Galau', 'bgt', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc2 = dummy_doc.apply(lambda doc: word_token_spacy(doc.iloc[0]),axis=1)\n",
        "print(type(dummy_doc2))\n",
        "dummy_doc2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOeYIommyt9U",
        "outputId": "a1136dfa-6f2f-4122-903f-14fd5b340885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [utk, kamu, yg, disana, ,, sdh, makan, belum, ?]\n",
              "1    [Bangkai, 120, lumba-lumba, ditemukan, di, sun...\n",
              "2    [Gue, ga, suka, makan, bakso, ,, jangan, dipak...\n",
              "3    [Galau, bgt, mau, dukung, Ji, Chang, Wook, ata...\n",
              "4    [Kasus, Covid, -, 19, bertambah, 40.618, pada,...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_text_in_df(dummy_doc2.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-AakS6UyyTl",
        "outputId": "f821c843-8ae7-4a9b-dc97-325cabbc87d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['utk', 'kamu', 'yg', 'disana', ',', 'sdh', 'makan', 'belum', '?']\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'di', 'sungai', 'Amazon', 'selama', 'seminggu', 'terakhir', '.']\n",
            "['Gue', 'ga', 'suka', 'makan', 'bakso', ',', 'jangan', 'dipaksaaa', '!', '!', '!']\n",
            "['Galau', 'bgt', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<3']\n",
            "['Kasus', 'Covid', '-', '19', 'bertambah', '40.618', 'pada', 'Kamis', '(', '10', '/', '2', ')', ',', 'sehingga', 'total', 'kasus', 'mencapai', '4.667.554', '.', 'Sebanyak', '4.234.510', 'orang', 'telah', 'sembuh', ',', 'dan', '144.858', 'meninggal', 'dunia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_text = \"I don't like your attitude! I'll report you to your parents!\"\n",
        "print(word_token_default(eng_text))\n",
        "print(word_token_spacy(eng_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcywGxKey1Gq",
        "outputId": "68f3c1cf-ec64-4641-9196-65250185a4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', \"don't\", 'like', 'your', 'attitude!', \"I'll\", 'report', 'you', 'to', 'your', 'parents!']\n",
            "['I', \"don't\", 'like', 'your', 'attitude', '!', \"I'll\", 'report', 'you', 'to', 'your', 'parents', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_eng = spacy.load(\"en_core_web_sm\")\n",
        "def word_token_spacy_eng(doc):\n",
        "  doc1 = nlp_eng(doc)\n",
        "  token = [token.text for token in doc1]\n",
        "  return token"
      ],
      "metadata": {
        "id": "IzHBkl4ky3xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_token_spacy_eng(eng_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJnzlxvEy52s",
        "outputId": "1d6dbd2f-c6e0-42e7-f976-344933b85921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'do', \"n't\", 'like', 'your', 'attitude', '!', 'I', \"'ll\", 'report', 'you', 'to', 'your', 'parents', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan NLTK #"
      ],
      "metadata": {
        "id": "MCEK8qnDODCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "gD7eAF6sy8Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UT4Jnady-rL",
        "outputId": "554dce25-4afb-4795-b023-4dca10a16be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_tokenize(dummy_doc.iloc[3,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTIMWiwYzLVP",
        "outputId": "dc331382-08f0-40c8-c26e-a90484f76452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Galau', 'bgt', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_tokenize(eng_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiTdGuAyzN_-",
        "outputId": "beec3579-01bd-48d9-8454-98cdfc6a0874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'do', \"n't\", 'like', 'your', 'attitude', '!', 'I', \"'ll\", 'report', 'you', 'to', 'your', 'parents', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc3 = dummy_doc.apply(lambda doc: word_tokenize(doc.iloc[0]),axis=1)\n",
        "print(type(dummy_doc3))\n",
        "dummy_doc3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE9OeFBYzQpR",
        "outputId": "0b64951b-7016-4566-c580-daa72b2ef6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [utk, kamu, yg, disana, ,, sdh, makan, belum, ?]\n",
              "1    [Bangkai, 120, lumba-lumba, ditemukan, di, sun...\n",
              "2    [Gue, ga, suka, makan, bakso, ,, jangan, dipak...\n",
              "3    [Galau, bgt, mau, dukung, Ji, Chang, Wook, ata...\n",
              "4    [Kasus, Covid-19, bertambah, 40.618, pada, Kam...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_text_in_df(dummy_doc3.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgKVeSQVzTv4",
        "outputId": "46ba060a-297e-4ada-91cd-b82f100b9926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['utk', 'kamu', 'yg', 'disana', ',', 'sdh', 'makan', 'belum', '?']\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'di', 'sungai', 'Amazon', 'selama', 'seminggu', 'terakhir', '.']\n",
            "['Gue', 'ga', 'suka', 'makan', 'bakso', ',', 'jangan', 'dipaksaaa', '!', '!', '!']\n",
            "['Galau', 'bgt', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<', '3']\n",
            "['Kasus', 'Covid-19', 'bertambah', '40.618', 'pada', 'Kamis', '(', '10/2', ')', ',', 'sehingga', 'total', 'kasus', 'mencapai', '4.667.554', '.', 'Sebanyak', '4.234.510', 'orang', 'telah', 'sembuh', ',', 'dan', '144.858', 'meninggal', 'dunia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisasi Karakter dalam Python #"
      ],
      "metadata": {
        "id": "mdbdDPzLOMrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def char_token(doc):\n",
        " token = [x for x in doc]\n",
        " return token"
      ],
      "metadata": {
        "id": "VVGpSvp3zW-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_token(dummy_doc.iloc[3,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nouul9zVzZll",
        "outputId": "317d13da-a01c-49d8-9648-7481f7e39bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['G', 'a', 'l', 'a', 'u', ' ', 'b', 'g', 't', ' ', 'm', 'a', 'u', ' ', 'd', 'u', 'k', 'u', 'n', 'g', ' ', 'J', 'i', ' ', 'C', 'h', 'a', 'n', 'g', ' ', 'W', 'o', 'o', 'k', ' ', 'a', 't', 'a', 'u', ' ', 'W', 'i', ' ', 'H', 'a', ' ', 'J', 'o', 'o', 'n', '.', '.', '.', ' ', 'S', 'e', 'm', 'u', 'a', 'n', 'y', 'a', ' ', 'k', 'a', 's', 'i', 'a', 'n', ' ', 'h', 'u', 'h', 'u', '.', '.', ' ', 'T', 'h', 'e', ' ', 'W', 'o', 'r', 's', 't', ' ', 'o', 'f', ' ', 'E', 'v', 'i', 'l', ' ', 's', 'e', 'r', 'u', 'u', 'u', 'u', ' ', 'b', 'g', 't', '!', ' ', '<', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc4 = dummy_doc.apply(lambda doc: char_token(doc.iloc[0]),axis=1)\n",
        "print(type(dummy_doc4))\n",
        "dummy_doc4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUBXDCVwzbwt",
        "outputId": "1901fa5e-3cf6-418c-cbc5-61e155408337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [u, t, k,  , k, a, m, u,  , y, g,  , d, i, s, ...\n",
              "1    [B, a, n, g, k, a, i,  , 1, 2, 0,  , l, u, m, ...\n",
              "2    [G, u, e,  , g, a,  , s, u, k, a,  , m, a, k, ...\n",
              "3    [G, a, l, a, u,  , b, g, t,  , m, a, u,  , d, ...\n",
              "4    [K, a, s, u, s,  , C, o, v, i, d, -, 1, 9,  , ...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_text_in_df(dummy_doc4.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AvJ-e2xzezd",
        "outputId": "8c10f217-5eae-477b-c132-8b3e62ab47dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['u', 't', 'k', ' ', 'k', 'a', 'm', 'u', ' ', 'y', 'g', ' ', 'd', 'i', 's', 'a', 'n', 'a', ',', ' ', 's', 'd', 'h', ' ', 'm', 'a', 'k', 'a', 'n', ' ', 'b', 'e', 'l', 'u', 'm', '?']\n",
            "['B', 'a', 'n', 'g', 'k', 'a', 'i', ' ', '1', '2', '0', ' ', 'l', 'u', 'm', 'b', 'a', '-', 'l', 'u', 'm', 'b', 'a', ' ', 'd', 'i', 't', 'e', 'm', 'u', 'k', 'a', 'n', ' ', 'd', 'i', ' ', 's', 'u', 'n', 'g', 'a', 'i', ' ', 'A', 'm', 'a', 'z', 'o', 'n', ' ', 's', 'e', 'l', 'a', 'm', 'a', ' ', 's', 'e', 'm', 'i', 'n', 'g', 'g', 'u', ' ', 't', 'e', 'r', 'a', 'k', 'h', 'i', 'r', '.']\n",
            "['G', 'u', 'e', ' ', 'g', 'a', ' ', 's', 'u', 'k', 'a', ' ', 'm', 'a', 'k', 'a', 'n', ' ', 'b', 'a', 'k', 's', 'o', ',', ' ', 'j', 'a', 'n', 'g', 'a', 'n', ' ', 'd', 'i', 'p', 'a', 'k', 's', 'a', 'a', 'a', '!', '!', '!']\n",
            "['G', 'a', 'l', 'a', 'u', ' ', 'b', 'g', 't', ' ', 'm', 'a', 'u', ' ', 'd', 'u', 'k', 'u', 'n', 'g', ' ', 'J', 'i', ' ', 'C', 'h', 'a', 'n', 'g', ' ', 'W', 'o', 'o', 'k', ' ', 'a', 't', 'a', 'u', ' ', 'W', 'i', ' ', 'H', 'a', ' ', 'J', 'o', 'o', 'n', '.', '.', '.', ' ', 'S', 'e', 'm', 'u', 'a', 'n', 'y', 'a', ' ', 'k', 'a', 's', 'i', 'a', 'n', ' ', 'h', 'u', 'h', 'u', '.', '.', ' ', 'T', 'h', 'e', ' ', 'W', 'o', 'r', 's', 't', ' ', 'o', 'f', ' ', 'E', 'v', 'i', 'l', ' ', 's', 'e', 'r', 'u', 'u', 'u', 'u', ' ', 'b', 'g', 't', '!', ' ', '<', '3']\n",
            "['K', 'a', 's', 'u', 's', ' ', 'C', 'o', 'v', 'i', 'd', '-', '1', '9', ' ', 'b', 'e', 'r', 't', 'a', 'm', 'b', 'a', 'h', ' ', '4', '0', '.', '6', '1', '8', ' ', 'p', 'a', 'd', 'a', ' ', 'K', 'a', 'm', 'i', 's', ' ', '(', '1', '0', '/', '2', ')', ',', ' ', 's', 'e', 'h', 'i', 'n', 'g', 'g', 'a', ' ', 't', 'o', 't', 'a', 'l', ' ', 'k', 'a', 's', 'u', 's', ' ', 'm', 'e', 'n', 'c', 'a', 'p', 'a', 'i', ' ', '4', '.', '6', '6', '7', '.', '5', '5', '4', '.', ' ', 'S', 'e', 'b', 'a', 'n', 'y', 'a', 'k', ' ', '4', '.', '2', '3', '4', '.', '5', '1', '0', ' ', 'o', 'r', 'a', 'n', 'g', ' ', 't', 'e', 'l', 'a', 'h', ' ', 's', 'e', 'm', 'b', 'u', 'h', ',', ' ', 'd', 'a', 'n', ' ', '1', '4', '4', '.', '8', '5', '8', ' ', 'm', 'e', 'n', 'i', 'n', 'g', 'g', 'a', 'l', ' ', 'd', 'u', 'n', 'i', 'a', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisasi Sub-kata dalam Python #"
      ],
      "metadata": {
        "id": "mqyeJ8PlOSeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFG7LUP5zhxY",
        "outputId": "57e91072-9463-47e4-e153-34370cb2019e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.31.0)\n",
            "Collecting sentencepiece (from bpemb)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (6.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2023.11.17)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.4 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bpemb import BPEmb"
      ],
      "metadata": {
        "id": "-FWk5Bpizpdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpemb_id = BPEmb(lang=\"id\",vs=200000, dim=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGHSEnMbzsCt",
        "outputId": "2b10f906-7f9f-4b54-e25f-538434b975f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/id/id.wiki.bpe.vs200000.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 3739973/3739973 [00:00<00:00, 4548473.31B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/id/id.wiki.bpe.vs200000.d300.w2v.bin.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 223740954/223740954 [00:09<00:00, 22848034.09B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bpemb_id.encode(dummy_doc.iloc[3,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NriZ6WHBz1m2",
        "outputId": "a7a3d9ec-55af-4dac-add1-2f6e1ff366eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['galau', 'bgt', 'mau', 'dukung', 'ji', 'chang', 'wook', 'atau', 'wi', 'ha', 'joon', '...', 'semuanya', 'kas', 'ian', 'h', 'uhu', '..', 'the', 'worst', 'of', 'evil', 'ser', 'uu', 'uu', 'bgt', '!', '<0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc5 = dummy_doc.apply(lambda doc: bpemb_id.encode(doc.iloc[0]),axis=1)\n",
        "print(type(dummy_doc5))\n",
        "dummy_doc5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xonwoQCSz5DC",
        "outputId": "f3515d75-64e7-4443-d71b-98801ab0be3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [utk, kamu, yg, disana, ,, sdh, makan, ...\n",
              "1    [bangkai, 000, lumba, -, lumba, ditemukan,...\n",
              "2    [gue, ga, suka, makan, bakso, ,, jangan,...\n",
              "3    [galau, bgt, mau, dukung, ji, chang, wo...\n",
              "4    [kasus, cov, id, -00, bertambah, 00.000, ...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_text_in_df(dummy_doc5.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTPcL3we0BBv",
        "outputId": "c3c296de-db00-4f93-95c3-cd82d6e61ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['utk', 'kamu', 'yg', 'disana', ',', 'sdh', 'makan', 'belum', '?']\n",
            "['bangkai', '000', 'lumba', '-', 'lumba', 'ditemukan', 'di', 'sungai', 'amazon', 'selama', 'seminggu', 'terakhir', '.']\n",
            "['gue', 'ga', 'suka', 'makan', 'bakso', ',', 'jangan', 'dipaksa', 'aa', '!!!']\n",
            "['galau', 'bgt', 'mau', 'dukung', 'ji', 'chang', 'wook', 'atau', 'wi', 'ha', 'joon', '...', 'semuanya', 'kas', 'ian', 'h', 'uhu', '..', 'the', 'worst', 'of', 'evil', 'ser', 'uu', 'uu', 'bgt', '!', '<0']\n",
            "['kasus', 'cov', 'id', '-00', 'bertambah', '00.000', 'pada', 'kamis', '(00/0', '),', 'sehingga', 'total', 'kasus', 'mencapai', '0.000.000.', 'sebanyak', '0.000.000', 'orang', 'telah', 'sembuh', ',', 'dan', '000.000', 'meninggal', 'dunia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Pre-processing sebelum tokenisasi #\n",
        "Tahap tokenisasi dalam python menyebabkan text yang bertipe string berubah menjadi list. Beberapa tahapan text preprocessing mengharuskan text yang kita miliki masih dalam bentuk string. Oleh karena itu, tahapan ini dilakukan sebelum kita melakukan tokenisasi. Tentu saja jika menggunakan bahasa pemrograman berbeda, hal ini bisa berubah. Adapun beberapa tahap text preprocessing yang termasuk dalam kriteria ini adalah sebagai berikut:\n",
        "\n",
        "* Case Folding (Capital/Non Capital letters)\n",
        "* Menghilangkan Tanda Baca (punctuation removal)\n",
        "* Menghapus whitepace (Whitespace removal)\n",
        "* Menghapus/mentransformasi angka"
      ],
      "metadata": {
        "id": "5xS9i6UxOjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "print(string.punctuation)\n",
        "print(string.digits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KlrhC050EeH",
        "outputId": "c4c03294-38e8-43ec-8374-50cfca027c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "0123456789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_token(doc):\n",
        "  # case folding\n",
        "  doc1 = doc.lower()\n",
        "  # punctuation removal+menghapus angka\n",
        "  doc2 = doc1.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
        "  # whitespace removal\n",
        "  doc3 = doc2.strip()\n",
        "  return doc3"
      ],
      "metadata": {
        "id": "2UKasKej0HWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_token_print(doc):\n",
        "  # case folding\n",
        "  doc1 = doc.lower()\n",
        "  print(\"Tahap Case Folding \\n\")\n",
        "  print(doc1,\"\\n\")\n",
        "  # punctuation removal+menghapus angka\n",
        "  doc2 = doc1.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
        "  print(\"Tahap Punctuation Removal dan menghapus angka \\n\")\n",
        "  print(doc2,\"\\n\")\n",
        "  # whitespace removal\n",
        "  print(\"Tahap Whitespace Removal \\n\")\n",
        "  doc3 = doc2.strip()\n",
        "  print(doc3)"
      ],
      "metadata": {
        "id": "7J-8wQ5S0Klo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print(dummy_doc.iloc[3,0])\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "pre_token(dummy_doc.iloc[3,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "zGF_epDM0NSN",
        "outputId": "b3c2e0e9-8acd-4c73-94d2-6aba46bed367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'galau bgt mau dukung ji chang wook atau wi ha joon semuanya kasian huhu the worst of evil seruuuu bgt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_token_print(dummy_doc.iloc[3,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI5Fon9O0QP9",
        "outputId": "12ab52eb-00ed-433e-9a3e-10b47fb4a33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahap Case Folding \n",
            "\n",
            "galau bgt mau dukung ji chang wook atau wi ha joon... semuanya kasian huhu.. the worst of evil seruuuu bgt! <3 \n",
            "\n",
            "Tahap Punctuation Removal dan menghapus angka \n",
            "\n",
            "galau bgt mau dukung ji chang wook atau wi ha joon semuanya kasian huhu the worst of evil seruuuu bgt  \n",
            "\n",
            "Tahap Whitespace Removal \n",
            "\n",
            "galau bgt mau dukung ji chang wook atau wi ha joon semuanya kasian huhu the worst of evil seruuuu bgt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc6 = dummy_doc.apply(lambda doc: pre_token(doc.iloc[0]),axis=1)\n",
        "print(type(dummy_doc6))\n",
        "dummy_doc6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-eHc5wM0TWj",
        "outputId": "8c8922ee-219b-4962-f6d4-155c73600716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   utk kamu yg disana sdh makan belum\n",
              "1    bangkai  lumbalumba ditemukan di sungai amazon...\n",
              "2             gue ga suka makan bakso jangan dipaksaaa\n",
              "3    galau bgt mau dukung ji chang wook atau wi ha ...\n",
              "4    kasus covid bertambah  pada kamis  sehingga to...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc)\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc6.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbPtSXuE0WOo",
        "outputId": "d4034d2f-5d0f-4db0-a3ba-dd937bddad3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "utk kamu yg disana, sdh makan belum?\n",
            "Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\n",
            "Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "utk kamu yg disana sdh makan belum\n",
            "bangkai  lumbalumba ditemukan di sungai amazon selama seminggu terakhir\n",
            "gue ga suka makan bakso jangan dipaksaaa\n",
            "galau bgt mau dukung ji chang wook atau wi ha joon semuanya kasian huhu the worst of evil seruuuu bgt\n",
            "kasus covid bertambah  pada kamis  sehingga total kasus mencapai  sebanyak  orang telah sembuh dan  meninggal dunia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menghapus StopWord dalam Python #\n",
        "Stopword merupakan kumpulan kata-kata yang sangat sering digunakan dalam suatu bahasa dan tidak memiliki makna khusus. Dalam python, stopword Bahasa Indonesia bisa diperoleh dari package Spacy dan NLTK.\n",
        "\n",
        "Untuk keperluan menghapus stopword dari text, kita akan mendefinisikan fungsi baru agar memudahkan perocess penghapusan"
      ],
      "metadata": {
        "id": "gn831Im0O5q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fungsi menghapus stopword\n",
        "def stopwords_removal(words,stopword):\n",
        "    return [word for word in words if word not in stopword]"
      ],
      "metadata": {
        "id": "5gMaByhD0aim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan Spacy #"
      ],
      "metadata": {
        "id": "OkYYJWr9PAQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.id.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "dEt2IIEy0djI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(STOP_WORDS))\n",
        "len(STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8MFIqOB0f78",
        "outputId": "e7808bd0-8ccc-4a93-dd38-771d6aefaadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'set'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "757"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(STOP_WORDS)[0:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvsET6AG0igl",
        "outputId": "a580b8cc-99ab-4cd2-b254-eea08d77900b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['berlangsung', 'dini', 'berujar', 'hendaklah', 'panjang', 'kapanpun', 'tentu', 'lah', 'harus', 'hampir', 'menyampaikan', 'selaku', 'perlunya', 'padanya', 'sela', 'diberi', 'justru', 'menanti-nanti', 'entahlah', 'penting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word(word,doc):\n",
        "  return list(filter(lambda x: word in x, doc))"
      ],
      "metadata": {
        "id": "7C3siMhe0lWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word(\"tidak\",list(STOP_WORDS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA43jUzt0nzs",
        "outputId": "18fd683f-2260-4fbd-9a27-4f2b3f1146e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['setidaknya', 'tidak', 'tidakkah', 'setidak-tidaknya', 'tidaklah']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print(dummy_doc.iloc[3,0])\n",
        "print(\"Sesudah Preprocessing \\n\")\n",
        "print(stopwords_removal(word_token_spacy(dummy_doc.iloc[3,0]),STOP_WORDS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nrE9K940qi0",
        "outputId": "477f7d55-f2d3-459b-881c-e86425b81fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['Galau', 'bgt', 'dukung', 'Ji', 'Chang', 'Wook', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords_removal(dummy_doc.iloc[3,0],STOP_WORDS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00RXLpgT0tgv",
        "outputId": "0cf0ddf2-36a2-442d-be5a-6887c0e7b671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['G', 'a', 'l', 'a', 'u', ' ', 'b', 'g', 't', ' ', 'm', 'a', 'u', ' ', 'd', 'u', 'k', 'u', 'n', 'g', ' ', 'J', 'i', ' ', 'C', 'h', 'a', 'n', 'g', ' ', 'W', 'o', 'o', 'k', ' ', 'a', 't', 'a', 'u', ' ', 'W', 'i', ' ', 'H', 'a', ' ', 'J', 'o', 'o', 'n', '.', '.', '.', ' ', 'S', 'e', 'm', 'u', 'a', 'n', 'y', 'a', ' ', 'k', 'a', 's', 'i', 'a', 'n', ' ', 'h', 'u', 'h', 'u', '.', '.', ' ', 'T', 'h', 'e', ' ', 'W', 'o', 'r', 's', 't', ' ', 'o', 'f', ' ', 'E', 'v', 'i', 'l', ' ', 's', 'e', 'r', 'u', 'u', 'u', 'u', ' ', 'b', 'g', 't', '!', ' ', '<', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc7 = dummy_doc.apply(lambda doc: stopwords_removal(word_token_spacy(doc.iloc[0]),STOP_WORDS),axis=1)\n",
        "print(type(dummy_doc7))\n",
        "dummy_doc7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGICa--20wLo",
        "outputId": "afbad646-daa7-4a3c-e2a7-591374d8ff7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  [utk, yg, disana, ,, sdh, makan, ?]\n",
              "1    [Bangkai, 120, lumba-lumba, ditemukan, sungai,...\n",
              "2    [Gue, ga, suka, makan, bakso, ,, dipaksaaa, !,...\n",
              "3    [Galau, bgt, dukung, Ji, Chang, Wook, Wi, Ha, ...\n",
              "4    [Kasus, Covid, -, 19, bertambah, 40.618, Kamis...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc)\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc7.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-tLhdg70y14",
        "outputId": "8d9922f7-c863-4d06-bfc7-b4721b38de34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "utk kamu yg disana, sdh makan belum?\n",
            "Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\n",
            "Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['utk', 'yg', 'disana', ',', 'sdh', 'makan', '?']\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'sungai', 'Amazon', 'seminggu', '.']\n",
            "['Gue', 'ga', 'suka', 'makan', 'bakso', ',', 'dipaksaaa', '!', '!', '!']\n",
            "['Galau', 'bgt', 'dukung', 'Ji', 'Chang', 'Wook', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<3']\n",
            "['Kasus', 'Covid', '-', '19', 'bertambah', '40.618', 'Kamis', '(', '10', '/', '2', ')', ',', 'total', 'mencapai', '4.667.554', '.', 'Sebanyak', '4.234.510', 'orang', 'sembuh', ',', '144.858', 'meninggal', 'dunia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan NLTK #"
      ],
      "metadata": {
        "id": "YQ6nwmYwPIzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "eUEKWPBD02ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mendapatkan stopword bahasa indonesia\n",
        "indo_stopwords = stopwords.words('indonesian')\n",
        "print(type(indo_stopwords))\n",
        "len(indo_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhR114zh04v0",
        "outputId": "e9a213f7-825f-4463-f4e4-2ee7202f0cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "758"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(indo_stopwords[0:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azclFtw607aF",
        "outputId": "6f1cb963-a4d2-4bcc-9a1f-956fe75d000b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_word(\"tidak\",indo_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02x-AY2J0-Yy",
        "outputId": "125aa6ae-cdf0-4b73-b233-16f2d3456e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['setidak-tidaknya', 'setidaknya', 'tidak', 'tidakkah', 'tidaklah']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print(dummy_doc.iloc[3,0])\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print(stopwords_removal(word_tokenize(dummy_doc.iloc[3,0]),indo_stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V8MsfLr1BA_",
        "outputId": "b2599948-0d58-4e80-ef8e-9240562bee47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['Galau', 'bgt', 'dukung', 'Ji', 'Chang', 'Wook', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords_removal(dummy_doc.iloc[3,0],indo_stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T9CUgdX1DvG",
        "outputId": "728e1213-0dac-4e9d-c078-8de3728e160b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['G', 'a', 'l', 'a', 'u', ' ', 'b', 'g', 't', ' ', 'm', 'a', 'u', ' ', 'd', 'u', 'k', 'u', 'n', 'g', ' ', 'J', 'i', ' ', 'C', 'h', 'a', 'n', 'g', ' ', 'W', 'o', 'o', 'k', ' ', 'a', 't', 'a', 'u', ' ', 'W', 'i', ' ', 'H', 'a', ' ', 'J', 'o', 'o', 'n', '.', '.', '.', ' ', 'S', 'e', 'm', 'u', 'a', 'n', 'y', 'a', ' ', 'k', 'a', 's', 'i', 'a', 'n', ' ', 'h', 'u', 'h', 'u', '.', '.', ' ', 'T', 'h', 'e', ' ', 'W', 'o', 'r', 's', 't', ' ', 'o', 'f', ' ', 'E', 'v', 'i', 'l', ' ', 's', 'e', 'r', 'u', 'u', 'u', 'u', ' ', 'b', 'g', 't', '!', ' ', '<', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc8 = dummy_doc.apply(lambda doc: stopwords_removal(word_tokenize(doc.iloc[0]),indo_stopwords),axis=1)\n",
        "print(type(dummy_doc8))\n",
        "dummy_doc8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpTk4-ky1GyN",
        "outputId": "8476e232-1706-40be-ac8f-54b05e1ebeff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  [utk, yg, disana, ,, sdh, makan, ?]\n",
              "1    [Bangkai, 120, lumba-lumba, ditemukan, sungai,...\n",
              "2    [Gue, ga, suka, makan, bakso, ,, dipaksaaa, !,...\n",
              "3    [Galau, bgt, dukung, Ji, Chang, Wook, Wi, Ha, ...\n",
              "4    [Kasus, Covid-19, bertambah, 40.618, Kamis, (,...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc)\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc8.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1dEDwX1Jb_",
        "outputId": "c301f2ec-a6e5-47d2-9582-eb6c6dd945f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "utk kamu yg disana, sdh makan belum?\n",
            "Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\n",
            "Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['utk', 'yg', 'disana', ',', 'sdh', 'makan', '?']\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'sungai', 'Amazon', 'seminggu', '.']\n",
            "['Gue', 'ga', 'suka', 'makan', 'bakso', ',', 'dipaksaaa', '!', '!', '!']\n",
            "['Galau', 'bgt', 'dukung', 'Ji', 'Chang', 'Wook', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasian', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'bgt', '!', '<', '3']\n",
            "['Kasus', 'Covid-19', 'bertambah', '40.618', 'Kamis', '(', '10/2', ')', ',', 'total', 'mencapai', '4.667.554', '.', 'Sebanyak', '4.234.510', 'orang', 'sembuh', ',', '144.858', 'meninggal', 'dunia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan Sastrawi #\n",
        "Selain untuk stemming, library Sastrawi juga mendukung proses filtering. Kita dapat menggunakan stopWordRemoverFactory dari modul sastrawi."
      ],
      "metadata": {
        "id": "BJymeCzoPOX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PySastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFk9ilkO1Nsm",
        "outputId": "09a86e10-388b-4a98-aa09-cbafcd5e3fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/210.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m92.2/210.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "stopword_sastrawi = factory.get_stop_words()\n",
        "print(stopword_sastrawi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88qF1-dZ1S67",
        "outputId": "8b92719a-353e-45a2-fe72-bd976361d746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara', 'antaranya', 'apa', 'apaan', 'apabila', 'apakah', 'apalagi', 'apatah', 'arti', 'artinya', 'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal', 'awalnya', 'b', 'bagai', 'bagaikan', 'bagaimana', 'bagaimanakah', 'bagaimanapun', 'bagainamakah', 'bagi', 'bagian', 'bahkan', 'bahwa', 'bahwasannya', 'bahwasanya', 'baik', 'baiklah', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah', 'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah', 'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah', 'benar', 'benarkah', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya', 'berapa', 'berapakah', 'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'beri', 'berikan', 'berikut', 'berikutnya', 'berjumlah', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan', 'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam', 'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap', 'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar', 'berupa', 'besar', 'betul', 'betulkah', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'bisakah', 'boleh', 'bolehkah', 'bolehlah', 'buat', 'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'c', 'cara', 'caranya', 'cukup', 'cukupkah', 'cukuplah', 'cuma', 'd', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi', 'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya', 'dialah', 'diantara', 'diantaranya', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat', 'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan', 'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan', 'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan', 'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah', 'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan', 'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan', 'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebut', 'disebutkan', 'disebutkannya', 'disini', 'disinilah', 'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk', 'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan', 'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'e', 'empat', 'enak', 'enggak', 'enggaknya', 'entah', 'entahlah', 'f', 'g', 'guna', 'gunakan', 'h', 'hadap', 'hai', 'hal', 'halo', 'hallo', 'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'helo', 'hello', 'hendak', 'hendaklah', 'hendaknya', 'hingga', 'i', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut', 'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'j', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban', 'jawabnya', 'jelas', 'jelaskan', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru', 'k', 'kadar', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kali', 'kalian', 'kami', 'kamilah', 'kamu', 'kamulah', 'kan', 'kapan', 'kapankah', 'kapanpun', 'karena', 'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya', 'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan', 'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kena', 'kenapa', 'kepada', 'kepadanya', 'kerja', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika', 'khusus', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang', 'l', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'laku', 'lalu', 'lama', 'lamanya', 'langsung', 'lanjut', 'lanjutnya', 'lebih', 'lewat', 'lihat', 'lima', 'luar', 'm', 'macam', 'maka', 'makanya', 'makin', 'maksud', 'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya', 'masih', 'masihkah', 'masing', 'masing-masing', 'masuk', 'mata', 'mau', 'maupun', 'melainkan', 'melakukan', 'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat', 'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan', 'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai', 'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti', 'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi', 'mendatangkan', 'menegaskan', 'mengakhiri', 'mengapa', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan', 'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan', 'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab', 'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjukkan', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan', 'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah', 'merupakan', 'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya', 'mohon', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'n', 'nah', 'naik', 'namun', 'nanti', 'nantinya', 'nya', 'nyaris', 'nyata', 'nyatanya', 'o', 'oleh', 'olehnya', 'orang', 'p', 'pada', 'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting', 'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama', 'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'q', 'r', 'rasa', 'rasanya', 'rupa', 'rupanya', 's', 'saat', 'saatnya', 'saja', 'sajalah', 'salam', 'saling', 'sama', 'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'sangkut', 'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian', 'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum', 'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', 'sebut', 'sebutlah', 'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya', 'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah', 'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekaranglah', 'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela', 'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya', 'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya', 'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian', 'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya', 'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai', 'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat', 'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai', 'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', 'sudahkah', 'sudahlah', 'supaya', 't', 'tadi', 'tadinya', 'tahu', 'tak', 'tambah', 'tambahnya', 'tampak', 'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya', 'telah', 'tempat', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak', 'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi', 'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan', 'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba', 'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'toh', 'tuju', 'tunjuk', 'turut', 'tutur', 'tuturnya', 'u', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'v', 'w', 'waduh', 'wah', 'wahai', 'waktunya', 'walau', 'walaupun', 'wong', 'x', 'y', 'ya', 'yaitu', 'yakin', 'yakni', 'yang', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print(dummy_doc.iloc[1,0])\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print(stopwords_removal(word_tokenize(dummy_doc.iloc[1,0]),stopword_sastrawi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg_hDRrc1Wm8",
        "outputId": "2bc10794-d441-450b-d3dc-dd1bed073a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'sungai', 'Amazon', 'seminggu', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Normalizarion/Noise Removal #\n",
        "Text Normalization merupakan process mengubah seperti mengubah bahasa tidak baku menjadi baku,mengubah singkatan.\n",
        "\n",
        "Untuk melakukan hal ini kita akan menggunakan daftar kata-kata tidak baku dan baku dari https://github.com/nasalsabila/kamus-alay yang sudah dalam bentuk file csv.. Kita akan mengimport file ini ke python dalam bentuk DataFrame"
      ],
      "metadata": {
        "id": "UkGDzTM_PUYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ep5KkBMu1Zia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indo_slang_word = pd.read_csv(\"https://raw.githubusercontent.com/nasalsabila/kamus-alay/master/colloquial-indonesian-lexicon.csv\")\n",
        "indo_slang_word.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "zoE6OiZs1b_0",
        "outputId": "86dd0b65-a3f7-4efb-a41f-6c370fa17d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     slang    formal  In-dictionary  \\\n",
              "0     woww       wow              1   \n",
              "1    aminn      amin              1   \n",
              "2      met   selamat              1   \n",
              "3   netaas   menetas              1   \n",
              "4  keberpa  keberapa              0   \n",
              "\n",
              "                                             context  category1 category2  \\\n",
              "0                                                wow   elongasi         0   \n",
              "1  Selamat ulang tahun kakak tulus semoga panjang...   elongasi         0   \n",
              "2  Met hari netaas kak!? Wish you all the best @t...  abreviasi         0   \n",
              "3  Met hari netaas kak!? Wish you all the best @t...   afiksasi  elongasi   \n",
              "4                           Birthday yg keberpa kak?  abreviasi         0   \n",
              "\n",
              "  category3  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7441008b-695a-4a70-b69b-8c27bfdcaa27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slang</th>\n",
              "      <th>formal</th>\n",
              "      <th>In-dictionary</th>\n",
              "      <th>context</th>\n",
              "      <th>category1</th>\n",
              "      <th>category2</th>\n",
              "      <th>category3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>woww</td>\n",
              "      <td>wow</td>\n",
              "      <td>1</td>\n",
              "      <td>wow</td>\n",
              "      <td>elongasi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aminn</td>\n",
              "      <td>amin</td>\n",
              "      <td>1</td>\n",
              "      <td>Selamat ulang tahun kakak tulus semoga panjang...</td>\n",
              "      <td>elongasi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>met</td>\n",
              "      <td>selamat</td>\n",
              "      <td>1</td>\n",
              "      <td>Met hari netaas kak!? Wish you all the best @t...</td>\n",
              "      <td>abreviasi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>netaas</td>\n",
              "      <td>menetas</td>\n",
              "      <td>1</td>\n",
              "      <td>Met hari netaas kak!? Wish you all the best @t...</td>\n",
              "      <td>afiksasi</td>\n",
              "      <td>elongasi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>keberpa</td>\n",
              "      <td>keberapa</td>\n",
              "      <td>0</td>\n",
              "      <td>Birthday yg keberpa kak?</td>\n",
              "      <td>abreviasi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7441008b-695a-4a70-b69b-8c27bfdcaa27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7441008b-695a-4a70-b69b-8c27bfdcaa27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7441008b-695a-4a70-b69b-8c27bfdcaa27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f8fde29-887d-4ce9-89c4-752dab861ce4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f8fde29-887d-4ce9-89c4-752dab861ce4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f8fde29-887d-4ce9-89c4-752dab861ce4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indo_slang_word.query(\"slang == 'loe'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "JjjFnkrt1k19",
        "outputId": "1669bc69-9ebe-4715-cc3f-d15e7ac816ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slang formal  In-dictionary  \\\n",
              "9179    loe     lo              1   \n",
              "10952   loe     lo              1   \n",
              "10954   loe     lo              1   \n",
              "10956   loe     lo              1   \n",
              "\n",
              "                                                 context   category1  \\\n",
              "9179   @angga_fabiyan tega u? Nenek moyang loe gua ma...  anaptiksis   \n",
              "10952  Bang @raditya_dika : loe anak tiri yah?? Adek ...  anaptiksis   \n",
              "10954  Bang @raditya_dika : loe anak tiri yah?? Adek ...  anaptiksis   \n",
              "10956  Bang @raditya_dika : loe anak tiri yah?? Adek ...  anaptiksis   \n",
              "\n",
              "      category2 category3  \n",
              "9179          0         0  \n",
              "10952         0         0  \n",
              "10954         0         0  \n",
              "10956         0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b4ac96d-8012-492a-93ff-3b59bb1cd75b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slang</th>\n",
              "      <th>formal</th>\n",
              "      <th>In-dictionary</th>\n",
              "      <th>context</th>\n",
              "      <th>category1</th>\n",
              "      <th>category2</th>\n",
              "      <th>category3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9179</th>\n",
              "      <td>loe</td>\n",
              "      <td>lo</td>\n",
              "      <td>1</td>\n",
              "      <td>@angga_fabiyan tega u? Nenek moyang loe gua ma...</td>\n",
              "      <td>anaptiksis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10952</th>\n",
              "      <td>loe</td>\n",
              "      <td>lo</td>\n",
              "      <td>1</td>\n",
              "      <td>Bang @raditya_dika : loe anak tiri yah?? Adek ...</td>\n",
              "      <td>anaptiksis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10954</th>\n",
              "      <td>loe</td>\n",
              "      <td>lo</td>\n",
              "      <td>1</td>\n",
              "      <td>Bang @raditya_dika : loe anak tiri yah?? Adek ...</td>\n",
              "      <td>anaptiksis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10956</th>\n",
              "      <td>loe</td>\n",
              "      <td>lo</td>\n",
              "      <td>1</td>\n",
              "      <td>Bang @raditya_dika : loe anak tiri yah?? Adek ...</td>\n",
              "      <td>anaptiksis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b4ac96d-8012-492a-93ff-3b59bb1cd75b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b4ac96d-8012-492a-93ff-3b59bb1cd75b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b4ac96d-8012-492a-93ff-3b59bb1cd75b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd1e9381-b3bf-44cc-a735-14abf2708731\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd1e9381-b3bf-44cc-a735-14abf2708731')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd1e9381-b3bf-44cc-a735-14abf2708731 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_slang_word(doc,slang_word):\n",
        "    for index in  range(0,len(doc)-1):\n",
        "        index_slang = slang_word.slang==doc[index]\n",
        "        formal = list(set(slang_word[index_slang].formal))\n",
        "        if len(formal)==1:\n",
        "            doc[index]=formal[0]\n",
        "    return doc"
      ],
      "metadata": {
        "id": "UZt-EE-s1wrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print(dummy_doc.iloc[2,0])\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print(replace_slang_word(word_token_spacy(dummy_doc.iloc[2,0]),indo_slang_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IagYDPow1ze7",
        "outputId": "8101c0b8-a1e9-45ad-a02f-516b0bf39995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['Gue', 'enggak', 'suka', 'makan', 'bakso', ',', 'jangan', 'dipaksaaa', '!', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_doc9 = dummy_doc.apply(lambda doc: replace_slang_word(word_token_spacy(doc.iloc[0]),indo_slang_word),axis=1)\n",
        "print(type(dummy_doc9))\n",
        "dummy_doc9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRd4CVjb12K3",
        "outputId": "2a5129e7-70c9-48b9-b918-71fed33284f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [untuk, kamu, yang, disana, ,, sudah, makan, b...\n",
              "1    [Bangkai, 120, lumba-lumba, ditemukan, di, sun...\n",
              "2    [Gue, enggak, suka, makan, bakso, ,, jangan, d...\n",
              "3    [Galau, banget, mau, dukung, Ji, Chang, Wook, ...\n",
              "4    [Kasus, Covid, -, 19, bertambah, 40.618, pada,...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc)\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print_text_in_df(dummy_doc9.to_frame(name=\"text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvhUlgne15gR",
        "outputId": "0fa2c84c-45a3-4663-ec34-7937afa6d6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "utk kamu yg disana, sdh makan belum?\n",
            "Bangkai 120 lumba-lumba ditemukan di sungai Amazon selama seminggu terakhir.\n",
            "Gue ga suka makan bakso, jangan dipaksaaa!!!\n",
            "Galau bgt mau dukung Ji Chang Wook atau Wi Ha Joon... Semuanya kasian huhu.. The Worst of Evil seruuuu bgt! <3\n",
            "Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "['untuk', 'kamu', 'yang', 'disana', ',', 'sudah', 'makan', 'belum', '?']\n",
            "['Bangkai', '120', 'lumba-lumba', 'ditemukan', 'di', 'sungai', 'Amazon', 'selama', 'seminggu', 'terakhir', '.']\n",
            "['Gue', 'enggak', 'suka', 'makan', 'bakso', ',', 'jangan', 'dipaksaaa', '!', '!', '!']\n",
            "['Galau', 'banget', 'mau', 'dukung', 'Ji', 'Chang', 'Wook', 'atau', 'Wi', 'Ha', 'Joon', '...', 'Semuanya', 'kasihan', 'huhu', '..', 'The', 'Worst', 'of', 'Evil', 'seruuuu', 'banget', '!', '<3']\n",
            "['Kasus', 'Covid', '-', '19', 'bertambah', '40.618', 'pada', 'Kamis', '(', '10', '/', '2', ')', ',', 'sehingga', 'total', 'kasus', 'mencapai', '4.667.554', '.', 'Sebanyak', '4.234.510', 'orang', 'telah', 'sembuh', ',', 'dan', '144.858', 'meninggal', 'dunia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming/Lemmatization #\n",
        "Stemming adalah proses menghilangkan infleksi kata ke bentuk dasarnya, namun bentuk dasar tersebut tidak berarti sama dengan akar kata (root word). Misalnya kata mendengarkan, dengarkan, didengarkan akan ditransformasi menjadi kata dengar.\n",
        "\n",
        "Idenya adalah ketika kita mencari dokumen cara membuka lemari, kita juga ingin melihat dokumen yang menyebutkan cara terbuka lemari atau cara dibuka lemari meskipun terdengar tidak enak. Tentunya kita ingin mencocokan semua variasi kata untuk memunculkan dokumen yang paling relevan.\n",
        "\n",
        "Stemming adalah proses menghasilkan varian morfologi dari kata dasar / dasar. Program stemming biasanya disebut sebagai algoritma stemming atau stemmer. Algoritme stemming mereduksi kata-kata menghasilkan menjadi hasil dan percintaan menjadi cinta.\n",
        "\n",
        "Berbeda dengan stemming, lemmatization mempertimbangkan kosakata(vocabulary) lengkap suatu bahasa untuk menerapkan analisis morfologi pada kata-kata. Lemma dari 'menaruh' adalah 'taruh' dan lemma dari 'menyapu' adalah 'sapu'.\n",
        "\n",
        "# Stemming bahasa indonesia menggunakan Python Sastrawi #\n",
        "Proses stemming antara satu bahasa dengan bahasa yang lain tentu berbeda. Contohnya pada teks berbahasa inggris, proses yang diperlukan hanya proses menghilangkan sufiks. Sedangkan pada teks berbahasa Indonesia semua kata imbuhan baik itu sufiks dan prefiks juga dihilangkan.\n",
        "\n",
        "Untuk melakukan stemming bahasa Indonesia kita dapat menggunakan library Python Sastrawi yang sudah kita siapkan di awal. Library Sastrawi menerapkan Algoritma Nazief dan Adriani dalam melakukan stemming bahasa Indonesia."
      ],
      "metadata": {
        "id": "RYYOkgbHPdty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "kalimat = \"Andi kerap melakukan transaksi rutin secara daring atau online. Menurut Andi belanja online lebih praktis & murah.\"\n",
        "hasil = stemmer.stem(kalimat)\n",
        "print(hasil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uKoECjg1-8N",
        "outputId": "7a9335fe-0860-4add-df9e-cc3a44f019d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "andi kerap laku transaksi rutin cara daring atau online turut andi belanja online lebih praktis murah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sebelum Preprocessing \\n\")\n",
        "print(dummy_doc.iloc[4,0])\n",
        "print(\"\\nSesudah Preprocessing \\n\")\n",
        "print(stemmer.stem(dummy_doc.iloc[4,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOAECL1J3nKN",
        "outputId": "d537a35e-7d84-4da6-b96e-abed432d6c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebelum Preprocessing \n",
            "\n",
            "Kasus Covid-19 bertambah 40.618 pada Kamis (10/2), sehingga total kasus mencapai 4.667.554. Sebanyak 4.234.510 orang telah sembuh, dan 144.858 meninggal dunia.\n",
            "\n",
            "Sesudah Preprocessing \n",
            "\n",
            "kasus covid-19 tambah 40 618 pada kamis 10 2 sehingga total kasus capai 4 667 554 banyak 4 234 510 orang telah sembuh dan 144 858 tinggal dunia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming bahasa inggris #"
      ],
      "metadata": {
        "id": "JzcIsJQdPnCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__qtzuvD3ySg",
        "outputId": "bd03a285-f4c9-40e8-a88a-cbefc84716bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('jump', 'jump', 'jump')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps.stem('lying'), ps.stem('strange')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVX6szY331lg",
        "outputId": "93b6e770-793b-47c5-f414-2a75e15deec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lie', 'strang')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lancaster Stemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "ls = LancasterStemmer()\n",
        "\n",
        "ls.stem('jumping'), ls.stem('jumps'), ls.stem('jumped')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrA9vzk34Aq",
        "outputId": "96691711-f36d-4d0a-bb9f-4e87a111abc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('jump', 'jump', 'jump')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls.stem('lying'), ls.stem('strange')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uHM-G6536gi",
        "outputId": "9f66a71b-8193-436f-fcf3-6c3c5662561e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lying', 'strange')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regex based stemmer\n",
        "from nltk.stem import RegexpStemmer\n",
        "rs = RegexpStemmer('ing$|s$|ed$', min=4)\n",
        "rs.stem('jumping'), rs.stem('jumps'), rs.stem('jumped')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdaS8Dfd4Lk3",
        "outputId": "39fad191-af74-4286-8985-1ab3feaf5bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('jump', 'jump', 'jump')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs.stem('lying'), rs.stem('strange')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_MVzRRH4NpH",
        "outputId": "55c82bae-8242-49c1-8095-567a9d78ee75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ly', 'strange')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Snowball Stemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "ss = SnowballStemmer(\"german\")\n",
        "print('Supported Languages:', SnowballStemmer.languages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0mW4J5A4QE0",
        "outputId": "26971230-3a31-4f02-c6ac-3001b153ada5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supported Languages: ('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming on German words\n",
        "# autobahnen -> cars\n",
        "# autobahn -> car\n",
        "ss.stem('autobahnen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "C21FxUIl4SnB",
        "outputId": "a9b781dc-637b-4944-e04e-1772de6af57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'autobahn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# springen -> jumping\n",
        "# spring -> jump\n",
        "ss.stem('springen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PhtcIexx4U8g",
        "outputId": "43334e53-88e2-47d0-bf8a-40c5f9d37edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spring'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_stemmer(text):\n",
        "    ps = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sJT92lpA4XAx",
        "outputId": "73d84b21-9326-4001-c593-6aa1fbe2a7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my system keep crash hi crash yesterday, our crash daili'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization bahasa Indonesia #"
      ],
      "metadata": {
        "id": "R77E6g2-Ps5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pM1tcZL4Z3k",
        "outputId": "6552e84d-1215-4373-9f6a-ab522df8e9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nlp-id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnBiPe4T4cDn",
        "outputId": "9bd1a954-9560-4276-96d4-e57f579d619f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlp-id\n",
            "  Downloading nlp_id-0.1.15.0.tar.gz (54.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (1.2.2)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (3.8.1)\n",
            "Collecting wget==3.2 (from nlp-id)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytest==7.3.1 (from nlp-id)\n",
            "  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (4.66.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->nlp-id) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->nlp-id) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->nlp-id) (3.2.0)\n",
            "Building wheels for collected packages: nlp-id, wget\n",
            "  Building wheel for nlp-id (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp-id: filename=nlp_id-0.1.15.0-py3-none-any.whl size=58153891 sha256=18115a1dbd26a1dc4f03ac4c78c7306f8cfb21d0f2ad894eecd5ba1b85a48103\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/34/2a/deaf7b7896a1eed336b874e1a7732588d40bb7bdc0a824e73e\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=dd1efead09b8dd94a50dec48b1b4cf80097065d2c637c3930d12de8dd53912a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built nlp-id wget\n",
            "Installing collected packages: wget, pytest, nlp-id\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "Successfully installed nlp-id-0.1.15.0 pytest-7.3.1 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import json\n",
        "from nlp_id.tokenizer import Tokenizer\n",
        "from nlp_id.stopword import StopWord\n",
        "from nlp_id.lemmatizer import Lemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "DAxoqMhx4rFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "berita_hoax = pd.read_csv('berita_HOAX_indonesia.csv', delimiter=\";\")\n",
        "berita_hoax.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DKhKHgU04t0g",
        "outputId": "f0d8fa25-4d2b-4bcf-89da-4b2d647389c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  kategori                                             berita\n",
              "0    valid  \"Gunung Agung erupsi untuk pertama kali pada 2...\n",
              "1    valid  \"Jakarta, CNN Indonesia -- Menteri BUMN Erick ...\n",
              "2    valid  \"Dosen Fakultas Kedokteran Hewan IPB, Yusuf Ri...\n",
              "3    valid  \"Jakarta - Dua anggota TNI, Serda N dan Serda ...\n",
              "4    valid  \"Akui Tembak Jatuh Pesawat Ukraina, Iran Tuai ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfd15d38-65ad-4b60-9232-617a9c138cd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kategori</th>\n",
              "      <th>berita</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>valid</td>\n",
              "      <td>\"Gunung Agung erupsi untuk pertama kali pada 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>valid</td>\n",
              "      <td>\"Jakarta, CNN Indonesia -- Menteri BUMN Erick ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>valid</td>\n",
              "      <td>\"Dosen Fakultas Kedokteran Hewan IPB, Yusuf Ri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>valid</td>\n",
              "      <td>\"Jakarta - Dua anggota TNI, Serda N dan Serda ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>valid</td>\n",
              "      <td>\"Akui Tembak Jatuh Pesawat Ukraina, Iran Tuai ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfd15d38-65ad-4b60-9232-617a9c138cd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfd15d38-65ad-4b60-9232-617a9c138cd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfd15d38-65ad-4b60-9232-617a9c138cd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-61e2ec22-83bc-44a7-9dd3-c871214341d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61e2ec22-83bc-44a7-9dd3-c871214341d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-61e2ec22-83bc-44a7-9dd3-c871214341d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "berita_hoax['kategori'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4MCs8rc5MLn",
        "outputId": "3008bee3-da42-4340-977b-cecfc107ac2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "valid    250\n",
              "hoax     250\n",
              "Name: kategori, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('combined_slang_words.txt') as f:\n",
        "    data0 = f.read()\n",
        "print(\"Data type before reconstruction : \", type(data0))\n",
        "formal_indo = json.loads(data0)\n",
        "print(\"Data type after reconstruction : \", type(formal_indo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8wts1dW5PE8",
        "outputId": "3bf1c855-3f9c-41c7-aeda-2c30b031770a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type before reconstruction :  <class 'str'>\n",
            "Data type after reconstruction :  <class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def informal_to_formal_indo(text):\n",
        "    res = \" \".join(formal_indo.get(ele, ele) for ele in text.split())\n",
        "    return(res)"
      ],
      "metadata": {
        "id": "T1g1SVn96U7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "stopword = StopWord()\n",
        "lemmatizer = Lemmatizer()"
      ],
      "metadata": {
        "id": "3-FPP2D56XEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"gue mau berpulang\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RgpgBe326Zoy",
        "outputId": "5d943dac-e4da-47f9-a6a7-0d423d294fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gue mau pulang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_tokenizer(doc):\n",
        "  #menghapus url\n",
        "  doc1 = re.sub(r\"https\\S+\", \"\",doc)\n",
        "  # lowercase\n",
        "  doc3 = doc1.lower()\n",
        "  # Text Normalization\n",
        "  doc4 = informal_to_formal_indo(doc3)\n",
        "  # punctuation removal+menghapus angka\n",
        "  doc5 = doc4.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
        "  # whitespace removal\n",
        "  doc6 = doc5.strip()\n",
        "  # stopword removal\n",
        "  doc7 = stopword.remove_stopword(doc6)\n",
        "  #Lemmatization\n",
        "  doc8=lemmatizer.lemmatize(doc7)\n",
        "  # tokenization\n",
        "  doc_token1 = tokenizer.tokenize(doc8)\n",
        "  return doc_token1"
      ],
      "metadata": {
        "id": "vIMfiFcb6aZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "berita_hoax.iloc[1,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "tnD6oyEf6f99",
        "outputId": "07c6d4a6-d5b2-4ff4-ee85-8f5b88d91bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Jakarta, CNN Indonesia -- Menteri BUMN Erick Thohir resmi menunjuk Basuki Tjahaja Purnama alias Ahok sebagai Komisaris Utama PT Pertamina (Persero). \"Basuki Tjahaja Purnama Komisaris Utama di Pertamina. Didampingi oleh pak Wamen BUMN Budi Gunadi Sadikin jadi Wakil Komisaris Utama di Pertamina,\" ujarnya, Jumat (22/11). Selain dua nama di atas, Erick juga menyodorkan Emma Sri Martini, eks direktur utama Telkomsel. Emma ditunjuk menjadi Direktur Keuangan Pertamina menggantikan Pahala Nugraha Mansury. Pergantian Pahala di Pertamina, sambung Erick, berkaitan dengan tugas barunya di PT Bank Tabungan Negara (Persero) Tbk. Pahala akan dibantu oleh Chandra Hamzah sebagai Komisaris Utama BTN. Erick mengklaim nama-nama tersebut di atas sudah melalui Tim Penilai Akhir (TPA). \"Saya hanya menyebutkan yang sudah melalui TPA. Yang tidak melalui TPA, saya tidak bisa komentar,\" tegas dia. Nama-nama pejabat baru Pertamina tersebut akan dilakukan segera pada Jumat ini atau paling lambat Senin (25/11). \"Pertamina bukan Tbk, jadi bisa disegerakan hari ini atau Senin,\" terang Erick.Sementara, pergantian pejabat BTN akan segera dilakukan melalui Rapat Umum Pemegang Saham (RUPS) pada akhir bulan ini.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect0 = CountVectorizer(tokenizer=my_tokenizer,token_pattern=None,lowercase=False)"
      ],
      "metadata": {
        "id": "Ir7pWzK_6oJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = count_vect0.fit_transform(berita_hoax[\"berita\"])\n",
        "features_df = pd.DataFrame(features.todense(), columns=count_vect0.get_feature_names_out())\n",
        "combined_df = pd.concat([berita_hoax[\"kategori\"], features_df], axis=1)\n",
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ZHJ5mISs6quo",
        "outputId": "47a60cb5-6f02-4c6f-8dd8-78c1ac45b718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    kategori  a  aa  aam  aamiin  ababa  abad  abai  abang  abbas  ...  \\\n",
              "0      valid  0   0    0       0      0     0     0      0      0  ...   \n",
              "1      valid  0   0    0       0      0     0     0      0      0  ...   \n",
              "2      valid  0   0    0       0      0     0     0      0      0  ...   \n",
              "3      valid  0   0    0       0      0     0     0      0      0  ...   \n",
              "4      valid  0   0    0       0      0     0     0      0      0  ...   \n",
              "..       ... ..  ..  ...     ...    ...   ...   ...    ...    ...  ...   \n",
              "495     hoax  0   1    0       0      0     0     0      0      0  ...   \n",
              "496     hoax  0   0    0       0      0     0     0      0      0  ...   \n",
              "497     hoax  0   0    0       0      0     0     0      0      0  ...   \n",
              "498     hoax  0   0    0       0      0     0     0      0      0  ...   \n",
              "499     hoax  0   0    0       0      0     0     0      0      0  ...   \n",
              "\n",
              "     zedong  zee  zeit  zholim  zhong  zimbabwe  zon  zona  zubaidah  zuhur  \n",
              "0         0    0     0       0      0         0    0     2         0      0  \n",
              "1         0    0     0       0      0         0    0     0         0      0  \n",
              "2         0    0     0       0      0         0    0     0         0      0  \n",
              "3         0    0     0       0      0         0    0     0         0      0  \n",
              "4         0    0     0       0      0         0    0     0         0      0  \n",
              "..      ...  ...   ...     ...    ...       ...  ...   ...       ...    ...  \n",
              "495       0    0     0       0      0         0    0     0         0      0  \n",
              "496       0    0     0       0      0         0    0     0         0      0  \n",
              "497       0    0     0       0      0         0    0     0         0      0  \n",
              "498       0    0     0       0      0         0    0     0         0      0  \n",
              "499       0    0     0       0      0         0    0     0         0      0  \n",
              "\n",
              "[500 rows x 6685 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39b51263-d7d6-4cdd-a7df-61dbbe4d4439\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kategori</th>\n",
              "      <th>a</th>\n",
              "      <th>aa</th>\n",
              "      <th>aam</th>\n",
              "      <th>aamiin</th>\n",
              "      <th>ababa</th>\n",
              "      <th>abad</th>\n",
              "      <th>abai</th>\n",
              "      <th>abang</th>\n",
              "      <th>abbas</th>\n",
              "      <th>...</th>\n",
              "      <th>zedong</th>\n",
              "      <th>zee</th>\n",
              "      <th>zeit</th>\n",
              "      <th>zholim</th>\n",
              "      <th>zhong</th>\n",
              "      <th>zimbabwe</th>\n",
              "      <th>zon</th>\n",
              "      <th>zona</th>\n",
              "      <th>zubaidah</th>\n",
              "      <th>zuhur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>valid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>valid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>valid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>valid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>valid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>hoax</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>hoax</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>hoax</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>hoax</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>hoax</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows  6685 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39b51263-d7d6-4cdd-a7df-61dbbe4d4439')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39b51263-d7d6-4cdd-a7df-61dbbe4d4439 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39b51263-d7d6-4cdd-a7df-61dbbe4d4439');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-070eade9-1a11-496c-9cd9-e60b25ab2b03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-070eade9-1a11-496c-9cd9-e60b25ab2b03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-070eade9-1a11-496c-9cd9-e60b25ab2b03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.to_csv(\"berita_hoax_indonesia_postprocess.csv\")"
      ],
      "metadata": {
        "id": "vuubvL_g6wic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization bahasa inggris #"
      ],
      "metadata": {
        "id": "flouvKmXP4qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "kaGXYj1m6zkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatize nouns\n",
        "print(wnl.lemmatize('cars', 'n'))\n",
        "print(wnl.lemmatize('men', 'n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PTVeR4v64G5",
        "outputId": "1569e536-cfa6-46c4-ebc0-afb26c211828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car\n",
            "men\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatize verbs\n",
        "print(wnl.lemmatize('running', 'v'))\n",
        "print(wnl.lemmatize('ate', 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frdhDm0c66We",
        "outputId": "9a210beb-555d-49b5-93a6-c42825a4260d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "eat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatize adjectives\n",
        "print(wnl.lemmatize('saddest', 'a'))\n",
        "print(wnl.lemmatize('fancier', 'a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgBXG01d69pd",
        "outputId": "111a541a-408d-431c-d43e-3445ee9eab97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sad\n",
            "fancy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ineffective lemmatization\n",
        "print(wnl.lemmatize('ate', 'n'))\n",
        "print(wnl.lemmatize('fancier', 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUb0TVGP6--K",
        "outputId": "24fe09e5-5f6d-4901-dd29-4a4c197fbd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ate\n",
            "fancier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# use spacy.load('en') if you have downloaded the language model en directly after install spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "text = 'My system keeps crashing his crashed yesterday, ours crashes daily'\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text\n",
        "\n",
        "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P7_YGo8h7Bar",
        "outputId": "d46afc81-4455-4d41-b284-52981e1777d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my system keep crash ! his crashed yesterday , ours crash daily'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text\n",
        "\n",
        "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JEvS5oB97F1S",
        "outputId": "df311524-64f3-4b8b-f639-f5acb1105ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "', , stopwords , computer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Text Wrangling #\n",
        "HTML Stripping"
      ],
      "metadata": {
        "id": "t0d0JbSJQDaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    [s.extract() for s in soup(['iframe', 'script'])]\n",
        "    stripped_text = soup.get_text()\n",
        "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "    return stripped_text"
      ],
      "metadata": {
        "id": "b-sGwvQf7Ka5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Accented Characters #"
      ],
      "metadata": {
        "id": "zC8oBewSQIg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "remove_accented_chars('Sm ccntd txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aOU6edFo7NPb",
        "outputId": "f2dc39ac-59b2-406d-a13e-d364dce6343a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Some Accented text'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expanding Contractions #"
      ],
      "metadata": {
        "id": "xpTaG3ePQM69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTJ69myC7QfP",
        "outputId": "72b579cd-072c-42fe-ff78-c240bf7a6085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "contractions.fix(\"Y'all can't expand contractions I'd think\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8XQBHWjs7V2-",
        "outputId": "d8784c08-15fa-47a4-8eeb-045f51bd8438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You all cannot expand contractions I would think'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Special Character #"
      ],
      "metadata": {
        "id": "NhIoxUWeQSNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "remove_special_characters(\"Well this was fun! What do you think? 123#@!\",\n",
        "                          remove_digits=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3rG2h4V_7cXB",
        "outputId": "22d64248-dfa1-4c4f-8c86-5af4e801d6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Well this was fun What do you think '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correcting Repeating Characters #"
      ],
      "metadata": {
        "id": "pZi9dZFZQWCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_word = 'finalllyyy'\n",
        "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "match_substitution = r'\\1\\2\\3'\n",
        "step = 1\n",
        "\n",
        "while True:\n",
        "    # remove one repeated character\n",
        "    new_word = repeat_pattern.sub(match_substitution,\n",
        "                                  old_word)\n",
        "    if new_word != old_word:\n",
        "         print('Step: {} Word: {}'.format(step, new_word))\n",
        "         step += 1 # update step\n",
        "         # update old word to last substituted state\n",
        "         old_word = new_word\n",
        "         continue\n",
        "    else:\n",
        "         print(\"Final word:\", new_word)\n",
        "         break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqRrbiVw7feU",
        "outputId": "b4694ad9-a747-4e9d-a67d-a66394468f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1 Word: finalllyy\n",
            "Step: 2 Word: finallly\n",
            "Step: 3 Word: finally\n",
            "Step: 4 Word: finaly\n",
            "Final word: finaly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import subprocess\n",
        "\n",
        "# Download and unzip wordnet\n",
        "try:\n",
        "    nltk.data.find('wordnet.zip')\n",
        "except:\n",
        "    nltk.download('wordnet', download_dir='/kaggle/working/')\n",
        "    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n",
        "    subprocess.run(command.split())\n",
        "    nltk.data.path.append('/kaggle/working/')\n",
        "\n",
        "# Now you can import the NLTK resources as usual\n",
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp4mpXGI7iTv",
        "outputId": "8ade041b-0ae1-43f2-ee22-a4b0ba6d9822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /kaggle/working/...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "old_word = 'finalllyyy'\n",
        "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "match_substitution = r'\\1\\2\\3'\n",
        "step = 1\n",
        "\n",
        "while True:\n",
        "    # check for semantically correct word\n",
        "    if wordnet.synsets(old_word):\n",
        "        print(\"Final correct word:\", old_word)\n",
        "        break\n",
        "    # remove one repeated character\n",
        "    new_word = repeat_pattern.sub(match_substitution,\n",
        "                                  old_word)\n",
        "    if new_word != old_word:\n",
        "        print('Step: {} Word: {}'.format(step, new_word))\n",
        "        step += 1 # update step\n",
        "        # update old word to last substituted state\n",
        "        old_word = new_word\n",
        "        continue\n",
        "    else:\n",
        "        print(\"Final word:\", new_word)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yac1LgF-7n6z",
        "outputId": "6acb81f1-5dd0-49e2-9303-1733a403526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1 Word: finalllyy\n",
            "Step: 2 Word: finallly\n",
            "Step: 3 Word: finally\n",
            "Final correct word: finally\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def remove_repeated_characters(tokens):\n",
        "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "    match_substitution = r'\\1\\2\\3'\n",
        "    def replace(old_word):\n",
        "        if wordnet.synsets(old_word):\n",
        "            return old_word\n",
        "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
        "        return replace(new_word) if new_word != old_word else new_word\n",
        "\n",
        "    correct_tokens = [replace(word) for word in tokens]\n",
        "    return correct_tokens"
      ],
      "metadata": {
        "id": "BwZs-tYm7rK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = 'My schooool is realllllyyy amaaazingggg'\n",
        "correct_tokens = remove_repeated_characters(nltk.word_tokenize(sample_sentence))\n",
        "' '.join(correct_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4VG-IZYD7toX",
        "outputId": "15ebaf43-450c-4940-8820-c07d38c9f355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My school is really amazing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correcting Spellings #"
      ],
      "metadata": {
        "id": "d0Q5YcHpQbk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, collections\n",
        "\n",
        "def tokens(text):\n",
        "    \"\"\"\n",
        "    Get all words from the corpus\n",
        "    \"\"\"\n",
        "    return re.findall('[a-z]+', text.lower())\n",
        "\n",
        "WORDS = tokens(open('big.txt').read())\n",
        "WORD_COUNTS = collections.Counter(WORDS)\n",
        "# top 10 words in corpus\n",
        "WORD_COUNTS.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66fKhIXU7wdz",
        "outputId": "53197720-5e04-461d-e748-e09ca816451a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 80030),\n",
              " ('of', 40025),\n",
              " ('and', 38313),\n",
              " ('to', 28766),\n",
              " ('in', 22050),\n",
              " ('a', 21155),\n",
              " ('that', 12512),\n",
              " ('he', 12401),\n",
              " ('was', 11410),\n",
              " ('it', 10681)]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edits0(word):\n",
        "    \"\"\"\n",
        "    Return all strings that are zero edits away\n",
        "    from the input word (i.e., the word itself).\n",
        "    \"\"\"\n",
        "    return {word}\n",
        "\n",
        "\n",
        "\n",
        "def edits1(word):\n",
        "    \"\"\"\n",
        "    Return all strings that are one edit away\n",
        "    from the input word.\n",
        "    \"\"\"\n",
        "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    def splits(word):\n",
        "        \"\"\"\n",
        "        Return a list of all possible (first, rest) pairs\n",
        "        that the input word is made of.\n",
        "        \"\"\"\n",
        "        return [(word[:i], word[i:])\n",
        "                for i in range(len(word)+1)]\n",
        "\n",
        "    pairs      = splits(word)\n",
        "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
        "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
        "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
        "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "\n",
        "def edits2(word):\n",
        "    \"\"\"Return all strings that are two edits away\n",
        "    from the input word.\n",
        "    \"\"\"\n",
        "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
      ],
      "metadata": {
        "id": "7XtQiEnc8pGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def known(words):\n",
        "    \"\"\"\n",
        "    Return the subset of words that are actually\n",
        "    in our WORD_COUNTS dictionary.\n",
        "    \"\"\"\n",
        "    return {w for w in words if w in WORD_COUNTS}"
      ],
      "metadata": {
        "id": "Rn_joKZQ8tw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input word\n",
        "In [409]: word = 'fianlly'\n",
        "\n",
        "# zero edit distance from input word\n",
        "edits0(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIxrfmLd8ydE",
        "outputId": "98976ffb-4d06-4975-c2f4-8bd75ea00ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fianlly'}"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# returns null set since it is not a valid word\n",
        "known(edits0(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nNDb0_f81la",
        "outputId": "d63ed95b-fee9-48d3-e7e1-1a470bd4b5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one edit distance from input word\n",
        "edits1(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ju7ESq28391",
        "outputId": "b39c0b69-5475-4b97-e6fe-f36e34e3b483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'afianlly',\n",
              " 'aianlly',\n",
              " 'bfianlly',\n",
              " 'bianlly',\n",
              " 'cfianlly',\n",
              " 'cianlly',\n",
              " 'dfianlly',\n",
              " 'dianlly',\n",
              " 'efianlly',\n",
              " 'eianlly',\n",
              " 'faanlly',\n",
              " 'faianlly',\n",
              " 'fainlly',\n",
              " 'fanlly',\n",
              " 'fbanlly',\n",
              " 'fbianlly',\n",
              " 'fcanlly',\n",
              " 'fcianlly',\n",
              " 'fdanlly',\n",
              " 'fdianlly',\n",
              " 'feanlly',\n",
              " 'feianlly',\n",
              " 'ffanlly',\n",
              " 'ffianlly',\n",
              " 'fganlly',\n",
              " 'fgianlly',\n",
              " 'fhanlly',\n",
              " 'fhianlly',\n",
              " 'fiaally',\n",
              " 'fiaanlly',\n",
              " 'fiablly',\n",
              " 'fiabnlly',\n",
              " 'fiaclly',\n",
              " 'fiacnlly',\n",
              " 'fiadlly',\n",
              " 'fiadnlly',\n",
              " 'fiaelly',\n",
              " 'fiaenlly',\n",
              " 'fiaflly',\n",
              " 'fiafnlly',\n",
              " 'fiaglly',\n",
              " 'fiagnlly',\n",
              " 'fiahlly',\n",
              " 'fiahnlly',\n",
              " 'fiailly',\n",
              " 'fiainlly',\n",
              " 'fiajlly',\n",
              " 'fiajnlly',\n",
              " 'fiaklly',\n",
              " 'fiaknlly',\n",
              " 'fiallly',\n",
              " 'fially',\n",
              " 'fialnlly',\n",
              " 'fialnly',\n",
              " 'fiamlly',\n",
              " 'fiamnlly',\n",
              " 'fianally',\n",
              " 'fianaly',\n",
              " 'fianblly',\n",
              " 'fianbly',\n",
              " 'fianclly',\n",
              " 'fiancly',\n",
              " 'fiandlly',\n",
              " 'fiandly',\n",
              " 'fianelly',\n",
              " 'fianely',\n",
              " 'fianflly',\n",
              " 'fianfly',\n",
              " 'fianglly',\n",
              " 'fiangly',\n",
              " 'fianhlly',\n",
              " 'fianhly',\n",
              " 'fianilly',\n",
              " 'fianily',\n",
              " 'fianjlly',\n",
              " 'fianjly',\n",
              " 'fianklly',\n",
              " 'fiankly',\n",
              " 'fianlaly',\n",
              " 'fianlay',\n",
              " 'fianlbly',\n",
              " 'fianlby',\n",
              " 'fianlcly',\n",
              " 'fianlcy',\n",
              " 'fianldly',\n",
              " 'fianldy',\n",
              " 'fianlely',\n",
              " 'fianley',\n",
              " 'fianlfly',\n",
              " 'fianlfy',\n",
              " 'fianlgly',\n",
              " 'fianlgy',\n",
              " 'fianlhly',\n",
              " 'fianlhy',\n",
              " 'fianlily',\n",
              " 'fianliy',\n",
              " 'fianljly',\n",
              " 'fianljy',\n",
              " 'fianlkly',\n",
              " 'fianlky',\n",
              " 'fianll',\n",
              " 'fianlla',\n",
              " 'fianllay',\n",
              " 'fianllb',\n",
              " 'fianllby',\n",
              " 'fianllc',\n",
              " 'fianllcy',\n",
              " 'fianlld',\n",
              " 'fianlldy',\n",
              " 'fianlle',\n",
              " 'fianlley',\n",
              " 'fianllf',\n",
              " 'fianllfy',\n",
              " 'fianllg',\n",
              " 'fianllgy',\n",
              " 'fianllh',\n",
              " 'fianllhy',\n",
              " 'fianlli',\n",
              " 'fianlliy',\n",
              " 'fianllj',\n",
              " 'fianlljy',\n",
              " 'fianllk',\n",
              " 'fianllky',\n",
              " 'fianlll',\n",
              " 'fianllly',\n",
              " 'fianllm',\n",
              " 'fianllmy',\n",
              " 'fianlln',\n",
              " 'fianllny',\n",
              " 'fianllo',\n",
              " 'fianlloy',\n",
              " 'fianllp',\n",
              " 'fianllpy',\n",
              " 'fianllq',\n",
              " 'fianllqy',\n",
              " 'fianllr',\n",
              " 'fianllry',\n",
              " 'fianlls',\n",
              " 'fianllsy',\n",
              " 'fianllt',\n",
              " 'fianllty',\n",
              " 'fianllu',\n",
              " 'fianlluy',\n",
              " 'fianllv',\n",
              " 'fianllvy',\n",
              " 'fianllw',\n",
              " 'fianllwy',\n",
              " 'fianllx',\n",
              " 'fianllxy',\n",
              " 'fianlly',\n",
              " 'fianllya',\n",
              " 'fianllyb',\n",
              " 'fianllyc',\n",
              " 'fianllyd',\n",
              " 'fianllye',\n",
              " 'fianllyf',\n",
              " 'fianllyg',\n",
              " 'fianllyh',\n",
              " 'fianllyi',\n",
              " 'fianllyj',\n",
              " 'fianllyk',\n",
              " 'fianllyl',\n",
              " 'fianllym',\n",
              " 'fianllyn',\n",
              " 'fianllyo',\n",
              " 'fianllyp',\n",
              " 'fianllyq',\n",
              " 'fianllyr',\n",
              " 'fianllys',\n",
              " 'fianllyt',\n",
              " 'fianllyu',\n",
              " 'fianllyv',\n",
              " 'fianllyw',\n",
              " 'fianllyx',\n",
              " 'fianllyy',\n",
              " 'fianllyz',\n",
              " 'fianllz',\n",
              " 'fianllzy',\n",
              " 'fianlmly',\n",
              " 'fianlmy',\n",
              " 'fianlnly',\n",
              " 'fianlny',\n",
              " 'fianloly',\n",
              " 'fianloy',\n",
              " 'fianlply',\n",
              " 'fianlpy',\n",
              " 'fianlqly',\n",
              " 'fianlqy',\n",
              " 'fianlrly',\n",
              " 'fianlry',\n",
              " 'fianlsly',\n",
              " 'fianlsy',\n",
              " 'fianltly',\n",
              " 'fianlty',\n",
              " 'fianluly',\n",
              " 'fianluy',\n",
              " 'fianlvly',\n",
              " 'fianlvy',\n",
              " 'fianlwly',\n",
              " 'fianlwy',\n",
              " 'fianlxly',\n",
              " 'fianlxy',\n",
              " 'fianly',\n",
              " 'fianlyl',\n",
              " 'fianlyly',\n",
              " 'fianlyy',\n",
              " 'fianlzly',\n",
              " 'fianlzy',\n",
              " 'fianmlly',\n",
              " 'fianmly',\n",
              " 'fiannlly',\n",
              " 'fiannly',\n",
              " 'fianolly',\n",
              " 'fianoly',\n",
              " 'fianplly',\n",
              " 'fianply',\n",
              " 'fianqlly',\n",
              " 'fianqly',\n",
              " 'fianrlly',\n",
              " 'fianrly',\n",
              " 'fianslly',\n",
              " 'fiansly',\n",
              " 'fiantlly',\n",
              " 'fiantly',\n",
              " 'fianully',\n",
              " 'fianuly',\n",
              " 'fianvlly',\n",
              " 'fianvly',\n",
              " 'fianwlly',\n",
              " 'fianwly',\n",
              " 'fianxlly',\n",
              " 'fianxly',\n",
              " 'fianylly',\n",
              " 'fianyly',\n",
              " 'fianzlly',\n",
              " 'fianzly',\n",
              " 'fiaolly',\n",
              " 'fiaonlly',\n",
              " 'fiaplly',\n",
              " 'fiapnlly',\n",
              " 'fiaqlly',\n",
              " 'fiaqnlly',\n",
              " 'fiarlly',\n",
              " 'fiarnlly',\n",
              " 'fiaslly',\n",
              " 'fiasnlly',\n",
              " 'fiatlly',\n",
              " 'fiatnlly',\n",
              " 'fiaully',\n",
              " 'fiaunlly',\n",
              " 'fiavlly',\n",
              " 'fiavnlly',\n",
              " 'fiawlly',\n",
              " 'fiawnlly',\n",
              " 'fiaxlly',\n",
              " 'fiaxnlly',\n",
              " 'fiaylly',\n",
              " 'fiaynlly',\n",
              " 'fiazlly',\n",
              " 'fiaznlly',\n",
              " 'fibanlly',\n",
              " 'fibnlly',\n",
              " 'ficanlly',\n",
              " 'ficnlly',\n",
              " 'fidanlly',\n",
              " 'fidnlly',\n",
              " 'fieanlly',\n",
              " 'fienlly',\n",
              " 'fifanlly',\n",
              " 'fifnlly',\n",
              " 'figanlly',\n",
              " 'fignlly',\n",
              " 'fihanlly',\n",
              " 'fihnlly',\n",
              " 'fiianlly',\n",
              " 'fiinlly',\n",
              " 'fijanlly',\n",
              " 'fijnlly',\n",
              " 'fikanlly',\n",
              " 'fiknlly',\n",
              " 'filanlly',\n",
              " 'filnlly',\n",
              " 'fimanlly',\n",
              " 'fimnlly',\n",
              " 'finally',\n",
              " 'finanlly',\n",
              " 'finlly',\n",
              " 'finnlly',\n",
              " 'fioanlly',\n",
              " 'fionlly',\n",
              " 'fipanlly',\n",
              " 'fipnlly',\n",
              " 'fiqanlly',\n",
              " 'fiqnlly',\n",
              " 'firanlly',\n",
              " 'firnlly',\n",
              " 'fisanlly',\n",
              " 'fisnlly',\n",
              " 'fitanlly',\n",
              " 'fitnlly',\n",
              " 'fiuanlly',\n",
              " 'fiunlly',\n",
              " 'fivanlly',\n",
              " 'fivnlly',\n",
              " 'fiwanlly',\n",
              " 'fiwnlly',\n",
              " 'fixanlly',\n",
              " 'fixnlly',\n",
              " 'fiyanlly',\n",
              " 'fiynlly',\n",
              " 'fizanlly',\n",
              " 'fiznlly',\n",
              " 'fjanlly',\n",
              " 'fjianlly',\n",
              " 'fkanlly',\n",
              " 'fkianlly',\n",
              " 'flanlly',\n",
              " 'flianlly',\n",
              " 'fmanlly',\n",
              " 'fmianlly',\n",
              " 'fnanlly',\n",
              " 'fnianlly',\n",
              " 'foanlly',\n",
              " 'foianlly',\n",
              " 'fpanlly',\n",
              " 'fpianlly',\n",
              " 'fqanlly',\n",
              " 'fqianlly',\n",
              " 'franlly',\n",
              " 'frianlly',\n",
              " 'fsanlly',\n",
              " 'fsianlly',\n",
              " 'ftanlly',\n",
              " 'ftianlly',\n",
              " 'fuanlly',\n",
              " 'fuianlly',\n",
              " 'fvanlly',\n",
              " 'fvianlly',\n",
              " 'fwanlly',\n",
              " 'fwianlly',\n",
              " 'fxanlly',\n",
              " 'fxianlly',\n",
              " 'fyanlly',\n",
              " 'fyianlly',\n",
              " 'fzanlly',\n",
              " 'fzianlly',\n",
              " 'gfianlly',\n",
              " 'gianlly',\n",
              " 'hfianlly',\n",
              " 'hianlly',\n",
              " 'ianlly',\n",
              " 'ifanlly',\n",
              " 'ifianlly',\n",
              " 'iianlly',\n",
              " 'jfianlly',\n",
              " 'jianlly',\n",
              " 'kfianlly',\n",
              " 'kianlly',\n",
              " 'lfianlly',\n",
              " 'lianlly',\n",
              " 'mfianlly',\n",
              " 'mianlly',\n",
              " 'nfianlly',\n",
              " 'nianlly',\n",
              " 'ofianlly',\n",
              " 'oianlly',\n",
              " 'pfianlly',\n",
              " 'pianlly',\n",
              " 'qfianlly',\n",
              " 'qianlly',\n",
              " 'rfianlly',\n",
              " 'rianlly',\n",
              " 'sfianlly',\n",
              " 'sianlly',\n",
              " 'tfianlly',\n",
              " 'tianlly',\n",
              " 'ufianlly',\n",
              " 'uianlly',\n",
              " 'vfianlly',\n",
              " 'vianlly',\n",
              " 'wfianlly',\n",
              " 'wianlly',\n",
              " 'xfianlly',\n",
              " 'xianlly',\n",
              " 'yfianlly',\n",
              " 'yianlly',\n",
              " 'zfianlly',\n",
              " 'zianlly'}"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get correct words from above set\n",
        "known(edits1(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2eBIHRC9ANq",
        "outputId": "fe27b1a3-942a-4b89-a982-1ffc20facd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'finally'}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two edit distances from input word\n",
        "edits2(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpgAZknG9CSO",
        "outputId": "e84ecb1a-fe5f-4cad-f4b6-f1c57fa76426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fniianlly',\n",
              " 'rkianlly',\n",
              " 'fianllem',\n",
              " 'efipnlly',\n",
              " 'fihanally',\n",
              " 'bfianlxy',\n",
              " 'fdanllfy',\n",
              " 'fiantllym',\n",
              " 'ficanlfy',\n",
              " 'hfianlldy',\n",
              " 'fibanlhy',\n",
              " 'fiatolly',\n",
              " 'yiaenlly',\n",
              " 'qiapnlly',\n",
              " 'fionxly',\n",
              " 'fiarlgly',\n",
              " 'fianllqyr',\n",
              " 'feuanlly',\n",
              " 'faiatlly',\n",
              " 'fyiaanlly',\n",
              " 'fiamnlty',\n",
              " 'jfiamnlly',\n",
              " 'finanlxy',\n",
              " 'abianlly',\n",
              " 'fiandllm',\n",
              " 'bxfianlly',\n",
              " 'fyaqnlly',\n",
              " 'fwianllty',\n",
              " 'fianljlyc',\n",
              " 'fianlfyq',\n",
              " 'fianfmy',\n",
              " 'fijnllwy',\n",
              " 'fitanvlly',\n",
              " 'fianzllyq',\n",
              " 'ianlley',\n",
              " 'fianklyk',\n",
              " 'fibanlbly',\n",
              " 'fiuanllyw',\n",
              " 'fixnllb',\n",
              " 'fwiandly',\n",
              " 'fianlggy',\n",
              " 'fianolx',\n",
              " 'fiqnlcly',\n",
              " 'fianulily',\n",
              " 'bficnlly',\n",
              " 'vfianllyh',\n",
              " 'fianldlzy',\n",
              " 'fcianlfly',\n",
              " 'dfianlley',\n",
              " 'fiabllyl',\n",
              " 'cficnlly',\n",
              " 'fvinnlly',\n",
              " 'fxianllw',\n",
              " 'fianlkv',\n",
              " 'fqianlfly',\n",
              " 'fionllq',\n",
              " 'fiamll',\n",
              " 'fiaxnllly',\n",
              " 'fianulyf',\n",
              " 'fianllwc',\n",
              " 'hianllyn',\n",
              " 'fiayjly',\n",
              " 'fiavnldy',\n",
              " 'ofiannly',\n",
              " 'fiuanllyr',\n",
              " 'fianldlye',\n",
              " 'fianolc',\n",
              " 'fhianllyh',\n",
              " 'fianglyc',\n",
              " 'filanltly',\n",
              " 'fiqnllw',\n",
              " 'finnllya',\n",
              " 'fiaullyf',\n",
              " 'fuianllvy',\n",
              " 'fiadnhly',\n",
              " 'fiamklly',\n",
              " 'fianlzlny',\n",
              " 'fiagylly',\n",
              " 'fiqajlly',\n",
              " 'vficanlly',\n",
              " 'fianillay',\n",
              " 'fianlayb',\n",
              " 'fwiankly',\n",
              " 'fiafnllmy',\n",
              " 'miaolly',\n",
              " 'fiangzly',\n",
              " 'vficnlly',\n",
              " 'fianlluay',\n",
              " 'fiaatly',\n",
              " 'fianallyv',\n",
              " 'fuunlly',\n",
              " 'fvianlkly',\n",
              " 'rixanlly',\n",
              " 'fveianlly',\n",
              " 'nianlle',\n",
              " 'fiaenljy',\n",
              " 'jilnlly',\n",
              " 'fkafnlly',\n",
              " 'fianzlliy',\n",
              " 'fwanllu',\n",
              " 'rianlln',\n",
              " 'fcanklly',\n",
              " 'didanlly',\n",
              " 'tfianllyx',\n",
              " 'fpanvlly',\n",
              " 'fbanlely',\n",
              " 'fianlmlu',\n",
              " 'wfianllye',\n",
              " 'fpanllwy',\n",
              " 'fianllcyb',\n",
              " 'fiaggnlly',\n",
              " 'tfiankly',\n",
              " 'fialhlly',\n",
              " 'fianljy',\n",
              " 'bijnlly',\n",
              " 'fiawnloly',\n",
              " 'flianllyx',\n",
              " 'fioanxlly',\n",
              " 'fodnlly',\n",
              " 'fienily',\n",
              " 'ianllyi',\n",
              " 'fianlxy',\n",
              " 'jfianlxly',\n",
              " 'fiavlwy',\n",
              " 'fqiacnlly',\n",
              " 'fianhllcy',\n",
              " 'fiantllyg',\n",
              " 'fianltd',\n",
              " 'fziaglly',\n",
              " 'gianlxy',\n",
              " 'fmanxly',\n",
              " 'fipannlly',\n",
              " 'fiazllyq',\n",
              " 'fiahnlbly',\n",
              " 'fiaxnkly',\n",
              " 'fianlgvly',\n",
              " 'tsianlly',\n",
              " 'fzianlxy',\n",
              " 'fhfanlly',\n",
              " 'fianlildy',\n",
              " 'fhiallly',\n",
              " 'fwianlloy',\n",
              " 'cianljy',\n",
              " 'fnianlny',\n",
              " 'sfianllm',\n",
              " 'fioanlwy',\n",
              " 'fianlljly',\n",
              " 'fikanllyv',\n",
              " 'fidqlly',\n",
              " 'ifianlli',\n",
              " 'fiasnllby',\n",
              " 'fianblaly',\n",
              " 'fisnlli',\n",
              " 'fiuaknlly',\n",
              " 'fiwnoly',\n",
              " 'fianlelhy',\n",
              " 'fcanslly',\n",
              " 'fiamlyl',\n",
              " 'fiankllwy',\n",
              " 'fianlljg',\n",
              " 'firanllay',\n",
              " 'fuianllfy',\n",
              " 'fiandlll',\n",
              " 'cfiafnlly',\n",
              " 'fianvlfly',\n",
              " 'fimnllyy',\n",
              " 'ffianloy',\n",
              " 'qfianlluy',\n",
              " 'wianlley',\n",
              " 'fiaollvy',\n",
              " 'fifanllye',\n",
              " 'filanlxly',\n",
              " 'piannlly',\n",
              " 'dfinanlly',\n",
              " 'fipanlwly',\n",
              " 'ofiaqlly',\n",
              " 'fimxlly',\n",
              " 'firnmlly',\n",
              " 'sfianllyl',\n",
              " 'feaplly',\n",
              " 'fianwllyy',\n",
              " 'fipnluy',\n",
              " 'fianxlyq',\n",
              " 'filanllly',\n",
              " 'fianxllyf',\n",
              " 'siannlly',\n",
              " 'mfiaxlly',\n",
              " 'fjarnlly',\n",
              " 'cfianlrly',\n",
              " 'lianlily',\n",
              " 'fianrlty',\n",
              " 'fianlnld',\n",
              " 'fiailuy',\n",
              " 'filaanlly',\n",
              " 'fihnlla',\n",
              " 'fianclhly',\n",
              " 'fpanluly',\n",
              " 'idfanlly',\n",
              " 'fvzianlly',\n",
              " 'fiaqnlwly',\n",
              " 'bfianxly',\n",
              " 'ufranlly',\n",
              " 'faiaxnlly',\n",
              " 'ofianflly',\n",
              " 'fianrlh',\n",
              " 'fianllx',\n",
              " 'fqtianlly',\n",
              " 'fiarnlcy',\n",
              " 'fkansly',\n",
              " 'fianlqv',\n",
              " 'fianlblny',\n",
              " 'fiadngly',\n",
              " 'fisanll',\n",
              " 'fiknllsy',\n",
              " 'fianljo',\n",
              " 'feianxly',\n",
              " 'fjanully',\n",
              " 'fiqnrlly',\n",
              " 'efinlly',\n",
              " 'ficanlxy',\n",
              " 'fianlkyc',\n",
              " 'pfjanlly',\n",
              " 'tiinlly',\n",
              " 'afhanlly',\n",
              " 'fiavjly',\n",
              " 'zfianaly',\n",
              " 'frzianlly',\n",
              " 'puianlly',\n",
              " 'fienlgly',\n",
              " 'xfiavlly',\n",
              " 'miantlly',\n",
              " 'cianlwly',\n",
              " 'fialnaly',\n",
              " 'fiasnllm',\n",
              " 'finxally',\n",
              " 'fianlmgly',\n",
              " 'fiafnllny',\n",
              " 'fianmay',\n",
              " 'fifnllz',\n",
              " 'fuicanlly',\n",
              " 'filanwlly',\n",
              " 'fvanlliy',\n",
              " 'ufianlloy',\n",
              " 'fiianllvy',\n",
              " 'fiwoanlly',\n",
              " 'finnllyf',\n",
              " 'fdanlcly',\n",
              " 'kfikanlly',\n",
              " 'kfianflly',\n",
              " 'fianfltly',\n",
              " 'fiwaplly',\n",
              " 'fianfyy',\n",
              " 'fianjlljy',\n",
              " 'fiatnzlly',\n",
              " 'fiabldly',\n",
              " 'mianloy',\n",
              " 'fienlls',\n",
              " 'fiakknlly',\n",
              " 'fiahanlly',\n",
              " 'gfianlld',\n",
              " 'vzfianlly',\n",
              " 'dfilnlly',\n",
              " 'fitablly',\n",
              " 'pianllh',\n",
              " 'fgannly',\n",
              " 'vipnlly',\n",
              " 'fizanbly',\n",
              " 'flanlyl',\n",
              " 'tfiadnlly',\n",
              " 'fzianlny',\n",
              " 'fximanlly',\n",
              " 'niyanlly',\n",
              " 'iiatlly',\n",
              " 'nfhianlly',\n",
              " 'pfianlty',\n",
              " 'fianllykg',\n",
              " 'fwianilly',\n",
              " 'fivnmlly',\n",
              " 'finallyi',\n",
              " 'fianelyb',\n",
              " 'fianqlk',\n",
              " 'afiarlly',\n",
              " 'fisanlkly',\n",
              " 'hfipnlly',\n",
              " 'filnqlly',\n",
              " 'fgiawnlly',\n",
              " 'tfiaknlly',\n",
              " 'fignzlly',\n",
              " 'fiacnzly',\n",
              " 'fiaslply',\n",
              " 'ffaolly',\n",
              " 'fkianlply',\n",
              " 'fiianlkly',\n",
              " 'fbaznlly',\n",
              " 'fianlxqy',\n",
              " 'fiaquly',\n",
              " 'fsianllqy',\n",
              " 'fibanilly',\n",
              " 'flivnlly',\n",
              " 'foanllye',\n",
              " 'fianllyew',\n",
              " 'fsafnlly',\n",
              " 'vfianlny',\n",
              " 'fpianlyy',\n",
              " 'kfiahnlly',\n",
              " 'fianzlf',\n",
              " 'fianlltc',\n",
              " 'fianlwqly',\n",
              " 'fianllmyk',\n",
              " 'fianglnly',\n",
              " 'fiafnlnly',\n",
              " 'fiamllry',\n",
              " 'mfiajnlly',\n",
              " 'firaqnlly',\n",
              " 'fnianllyw',\n",
              " 'yianlyl',\n",
              " 'fianxlh',\n",
              " 'fianjllf',\n",
              " 'dfianily',\n",
              " 'fianyhlly',\n",
              " 'flablly',\n",
              " 'fiarglly',\n",
              " 'kfianaly',\n",
              " 'bfiainlly',\n",
              " 'tfianzly',\n",
              " 'oianlaly',\n",
              " 'qianlli',\n",
              " 'fianzlle',\n",
              " 'kianllk',\n",
              " 'nfianlily',\n",
              " 'fianllwyy',\n",
              " 'finalty',\n",
              " 'falianlly',\n",
              " 'uianllym',\n",
              " 'faianllx',\n",
              " 'fianclsy',\n",
              " 'bianwly',\n",
              " 'filnlhy',\n",
              " 'fkanlcly',\n",
              " 'ufianslly',\n",
              " 'fcanily',\n",
              " 'fyianlljy',\n",
              " 'mfiablly',\n",
              " 'fkirnlly',\n",
              " 'flannlly',\n",
              " 'fcianlld',\n",
              " 'dfianldy',\n",
              " 'fionlay',\n",
              " 'kfianllvy',\n",
              " 'fioanllp',\n",
              " 'fianakly',\n",
              " 'vianlbly',\n",
              " 'ffiaylly',\n",
              " 'ianllvy',\n",
              " 'gfianlcly',\n",
              " 'fiadnllw',\n",
              " 'fqianljly',\n",
              " 'hianlaly',\n",
              " 'fignwlly',\n",
              " 'fianllrk',\n",
              " 'fianllvyo',\n",
              " 'fwanlls',\n",
              " 'fioslly',\n",
              " 'fvianmlly',\n",
              " 'fianlxuy',\n",
              " 'fwsanlly',\n",
              " 'ciahnlly',\n",
              " 'finlgy',\n",
              " 'fiaiily',\n",
              " 'kiqnlly',\n",
              " 'fwaynlly',\n",
              " 'ifavnlly',\n",
              " 'fitanllry',\n",
              " 'xiasnlly',\n",
              " 'fzanllny',\n",
              " 'efbanlly',\n",
              " 'mfilanlly',\n",
              " 'filadnlly',\n",
              " 'fiynllyy',\n",
              " 'fiarloy',\n",
              " 'fiafqly',\n",
              " 'fignlaly',\n",
              " 'fianlefly',\n",
              " 'fiatnllf',\n",
              " 'fiakllyq',\n",
              " 'fiadnllj',\n",
              " 'jfianly',\n",
              " 'lfiadlly',\n",
              " 'gfiaally',\n",
              " 'vfianlyy',\n",
              " 'fiasxlly',\n",
              " 'fiahlrly',\n",
              " 'fianldlq',\n",
              " 'fiagnglly',\n",
              " 'ftianllf',\n",
              " 'fkiawlly',\n",
              " 'fidnlyl',\n",
              " 'fpianrlly',\n",
              " 'facianlly',\n",
              " 'fiqanlky',\n",
              " 'fiabnllp',\n",
              " 'ltanlly',\n",
              " 'ofdianlly',\n",
              " 'fiinrly',\n",
              " 'fiarlsy',\n",
              " 'fianlnljy',\n",
              " 'fiagllyh',\n",
              " 'fianzlhly',\n",
              " 'fianllmyg',\n",
              " 'hiaynlly',\n",
              " 'fianlklyx',\n",
              " 'tianllv',\n",
              " 'fijanjlly',\n",
              " 'rfianlty',\n",
              " 'iianmly',\n",
              " 'fiqalnly',\n",
              " 'pfiadnlly',\n",
              " 'xianllyd',\n",
              " 'fiandllk',\n",
              " 'fiandlyc',\n",
              " 'qfianlky',\n",
              " 'sfianlfy',\n",
              " 'finanvlly',\n",
              " 'fivdnlly',\n",
              " 'xibanlly',\n",
              " 'fitanily',\n",
              " 'figantly',\n",
              " 'fiajnlly',\n",
              " 'fianhllyy',\n",
              " 'fvianslly',\n",
              " 'fpiwanlly',\n",
              " 'fianlwlyr',\n",
              " 'fianlolw',\n",
              " 'ftanlyy',\n",
              " 'foiaally',\n",
              " 'fianldp',\n",
              " 'fiaqlld',\n",
              " 'fiqanelly',\n",
              " 'fximnlly',\n",
              " 'fmanluy',\n",
              " 'fiapnilly',\n",
              " 'fianljlxy',\n",
              " 'ghianlly',\n",
              " 'sfvianlly',\n",
              " 'fimnllyx',\n",
              " 'sianllwy',\n",
              " 'hianclly',\n",
              " 'fnianllyq',\n",
              " 'kianllys',\n",
              " 'fianslmly',\n",
              " 'fhanll',\n",
              " 'fianllcye',\n",
              " 'fijanloly',\n",
              " 'nfaanlly',\n",
              " 'fianlun',\n",
              " 'fianxlvy',\n",
              " 'fiafnuly',\n",
              " 'faianllly',\n",
              " 'fianlclb',\n",
              " 'fijanluly',\n",
              " 'faaonlly',\n",
              " 'fipnllwy',\n",
              " 'wfianolly',\n",
              " 'fiantlzy',\n",
              " 'fqaylly',\n",
              " 'fianllxmy',\n",
              " 'fignllyq',\n",
              " 'rgianlly',\n",
              " 'fnanoly',\n",
              " 'fiacrlly',\n",
              " 'fianmllyu',\n",
              " 'fianllyfv',\n",
              " 'pfianly',\n",
              " 'lianully',\n",
              " 'figanbly',\n",
              " 'yiaelly',\n",
              " 'tfianllyd',\n",
              " 'qlfianlly',\n",
              " 'fiabnluly',\n",
              " 'fiwaully',\n",
              " 'fisaflly',\n",
              " 'fimnllr',\n",
              " 'fipnloy',\n",
              " 'fiidanlly',\n",
              " 'faanlly',\n",
              " 'fianjvy',\n",
              " 'gfiagnlly',\n",
              " 'fiaanlzly',\n",
              " 'dianllyj',\n",
              " 'fimnlpy',\n",
              " 'fjiajnlly',\n",
              " 'fianlklyh',\n",
              " 'fiwnclly',\n",
              " 'finllw',\n",
              " 'fkiaknlly',\n",
              " 'fjianlwy',\n",
              " 'fianjllyf',\n",
              " 'feianmly',\n",
              " 'fxanllc',\n",
              " 'ceianlly',\n",
              " 'fianltyw',\n",
              " 'fieganlly',\n",
              " 'ftanllj',\n",
              " 'gfienlly',\n",
              " 'fiyanllry',\n",
              " 'fiazll',\n",
              " 'lianllay',\n",
              " 'jtanlly',\n",
              " 'fiknoly',\n",
              " 'fidanllky',\n",
              " 'yfianlely',\n",
              " 'fianbllyl',\n",
              " 'fianxlv',\n",
              " 'fianngy',\n",
              " 'fianlwb',\n",
              " 'fiainflly',\n",
              " 'fiyplly',\n",
              " 'fianllaye',\n",
              " 'zfiwnlly',\n",
              " 'fiqanllvy',\n",
              " 'fivanlyly',\n",
              " 'fiazlluy',\n",
              " 'fmianlly',\n",
              " 'fiarxnlly',\n",
              " 'fyiaqlly',\n",
              " 'iirnlly',\n",
              " 'fiunllay',\n",
              " 'fianlzlry',\n",
              " 'fianavlly',\n",
              " 'dimanlly',\n",
              " 'xfiarlly',\n",
              " 'gianlsy',\n",
              " 'fianmzy',\n",
              " 'fmxanlly',\n",
              " 'fitnllym',\n",
              " 'ufianlely',\n",
              " 'lfianllsy',\n",
              " 'fiavnlzy',\n",
              " 'fipnltly',\n",
              " 'zianhly',\n",
              " 'fsianllz',\n",
              " 'fsanllyh',\n",
              " 'fianllvvy',\n",
              " 'fiactly',\n",
              " 'fianymly',\n",
              " 'foonlly',\n",
              " 'yfiannly',\n",
              " 'tpfianlly',\n",
              " 'fiankully',\n",
              " 'qiannlly',\n",
              " 'fihnzlly',\n",
              " 'fixavnlly',\n",
              " 'foianllyu',\n",
              " 'fianalvly',\n",
              " 'fianchly',\n",
              " 'fianlmuly',\n",
              " 'pianilly',\n",
              " 'fiasngly',\n",
              " 'siaglly',\n",
              " 'fikanllp',\n",
              " 'fiamunlly',\n",
              " 'firanlwly',\n",
              " 'ffiaelly',\n",
              " 'fiaqnlty',\n",
              " 'fianlglc',\n",
              " 'fiaztlly',\n",
              " 'fnrianlly',\n",
              " 'fieanllyr',\n",
              " 'ifianlwy',\n",
              " 'vfianlldy',\n",
              " 'fyqnlly',\n",
              " 'fiaullyo',\n",
              " 'xfianlrly',\n",
              " 'fwianllyr',\n",
              " 'fionluly',\n",
              " 'rfiajlly',\n",
              " 'oiaqlly',\n",
              " 'gfianclly',\n",
              " 'vfianllq',\n",
              " 'fihanllxy',\n",
              " 'fsanyly',\n",
              " 'fiaznllz',\n",
              " 'fianxlyy',\n",
              " 'tianlqy',\n",
              " 'fianllhyx',\n",
              " 'fiankmly',\n",
              " 'bafianlly',\n",
              " 'fmanfly',\n",
              " 'ffanlloy',\n",
              " 'foagnlly',\n",
              " 'ufianlwly',\n",
              " 'faanllyl',\n",
              " 'fiapelly',\n",
              " 'fianllwi',\n",
              " 'fiatrly',\n",
              " 'fiakllyv',\n",
              " 'fiafllcy',\n",
              " 'hivanlly',\n",
              " 'jianlsy',\n",
              " 'fiaulldy',\n",
              " 'fdanbly',\n",
              " 'fidanrlly',\n",
              " 'fqanllly',\n",
              " 'fianljlj',\n",
              " 'eianlty',\n",
              " 'ritanlly',\n",
              " 'fiakvnlly',\n",
              " 'fsanslly',\n",
              " 'gipnlly',\n",
              " 'fsanllj',\n",
              " 'fipxlly',\n",
              " 'frianllty',\n",
              " 'fifnlle',\n",
              " 'fiacnlby',\n",
              " 'feiaenlly',\n",
              " 'cxianlly',\n",
              " 'fiahllyc',\n",
              " 'ftanjlly',\n",
              " 'fijanlsly',\n",
              " 'fkeanlly',\n",
              " 'finoly',\n",
              " 'fianallt',\n",
              " 'fgicnlly',\n",
              " 'fzanluly',\n",
              " 'fitanllyf',\n",
              " 'fuanllwy',\n",
              " 'ehfianlly',\n",
              " 'fianlsyly',\n",
              " 'fiancrly',\n",
              " 'vixnlly',\n",
              " 'fianltyc',\n",
              " 'firtlly',\n",
              " 'fianllq',\n",
              " 'fxanlry',\n",
              " 'fienlln',\n",
              " 'fuiatlly',\n",
              " 'wikanlly',\n",
              " 'kianllty',\n",
              " 'fianjlyk',\n",
              " 'fiahnllty',\n",
              " 'fjafnlly',\n",
              " 'fmianljly',\n",
              " 'ziaflly',\n",
              " 'fsyianlly',\n",
              " 'fqianaly',\n",
              " 'fiallaly',\n",
              " 'pfiawnlly',\n",
              " 'fisanljly',\n",
              " 'mfbianlly',\n",
              " 'fioanllyq',\n",
              " 'fianillyv',\n",
              " 'fiknqly',\n",
              " 'hfianllj',\n",
              " 'cpianlly',\n",
              " 'fiantlyj',\n",
              " 'fijnlmy',\n",
              " 'fixnlvly',\n",
              " 'lially',\n",
              " 'fianrjly',\n",
              " 'fwianllzy',\n",
              " 'tiwanlly',\n",
              " 'tfipnlly',\n",
              " 'aianwlly',\n",
              " 'fianwey',\n",
              " 'tiaqnlly',\n",
              " 'bfiadnlly',\n",
              " 'fcnally',\n",
              " 'kfiatnlly',\n",
              " 'fianccly',\n",
              " 'figanllo',\n",
              " 'fiaonllxy',\n",
              " 'fismanlly',\n",
              " 'fianlzlt',\n",
              " 'fdatlly',\n",
              " 'ftanllhy',\n",
              " 'fianmllya',\n",
              " 'fiaznllyo',\n",
              " 'biankly',\n",
              " 'fiafnllh',\n",
              " 'fikkanlly',\n",
              " 'fitqnlly',\n",
              " 'yianllzy',\n",
              " 'fiiklly',\n",
              " 'ftianly',\n",
              " 'iuanlly',\n",
              " 'fraynlly',\n",
              " 'foijnlly',\n",
              " 'fiandlay',\n",
              " 'uianllq',\n",
              " 'fianzlgy',\n",
              " 'fciajlly',\n",
              " 'fianllmsy',\n",
              " 'fianllghy',\n",
              " 'tfiaunlly',\n",
              " 'tfianwly',\n",
              " 'fiasnllx',\n",
              " 'fifanllmy',\n",
              " 'fianlely',\n",
              " 'fisanoly',\n",
              " 'fitaslly',\n",
              " 'fiaenllyc',\n",
              " 'fgianlqly',\n",
              " 'hfianllyq',\n",
              " 'faidnlly',\n",
              " 'fianhlz',\n",
              " 'fiuaally',\n",
              " 'fiahnley',\n",
              " 'diaflly',\n",
              " 'fmwanlly',\n",
              " 'xfnanlly',\n",
              " 'fiznllay',\n",
              " 'fjaunlly',\n",
              " 'fianllxo',\n",
              " 'uianjly',\n",
              " 'fianlcm',\n",
              " 'fnanllx',\n",
              " 'fmiarnlly',\n",
              " 'fvlanlly',\n",
              " 'aianltly',\n",
              " 'fizanlldy',\n",
              " 'fiaolgly',\n",
              " 'fiunlky',\n",
              " 'franqly',\n",
              " 'gianllq',\n",
              " 'fiaulby',\n",
              " 'fianlnnly',\n",
              " 'fianbllyc',\n",
              " 'fianlpxy',\n",
              " 'filnflly',\n",
              " 'fianilily',\n",
              " 'fhianlhly',\n",
              " 'fijajlly',\n",
              " 'fienllfy',\n",
              " 'franlls',\n",
              " 'iianllby',\n",
              " 'wiaynlly',\n",
              " 'fianblxly',\n",
              " 'fianliloy',\n",
              " 'fdianljly',\n",
              " 'oimnlly',\n",
              " 'fiainllyx',\n",
              " 'ffanlily',\n",
              " 'fclianlly',\n",
              " 'fianvlluy',\n",
              " 'fiavtnlly',\n",
              " 'fxiagnlly',\n",
              " 'efganlly',\n",
              " 'fianvllvy',\n",
              " 'qixnlly',\n",
              " 'tianelly',\n",
              " 'fviantly',\n",
              " 'fiyanlqy',\n",
              " 'fikanllyq',\n",
              " 'fihanlrly',\n",
              " 'fgianllyo',\n",
              " 'mzianlly',\n",
              " 'fimnllyl',\n",
              " 'ziatlly',\n",
              " 'fiinllwy',\n",
              " 'fizanlyl',\n",
              " 'fiislly',\n",
              " 'fiaoolly',\n",
              " 'fiexanlly',\n",
              " 'fnanlli',\n",
              " 'fialey',\n",
              " 'fipanhly',\n",
              " 'fknnlly',\n",
              " 'fdanllj',\n",
              " 'fiahllzy',\n",
              " 'fiatllsy',\n",
              " 'flvianlly',\n",
              " 'fiutlly',\n",
              " 'spfianlly',\n",
              " 'fiavlliy',\n",
              " 'fpiadnlly',\n",
              " 'tiajnlly',\n",
              " 'fiacnllby',\n",
              " 'fboanlly',\n",
              " 'fianhlyv',\n",
              " 'fqanlyy',\n",
              " 'fianbllw',\n",
              " 'fbranlly',\n",
              " 'fxiranlly',\n",
              " 'franllyv',\n",
              " 'fianidy',\n",
              " 'fianlluyt',\n",
              " 'fianlimy',\n",
              " 'fianzllo',\n",
              " 'fiznlky',\n",
              " 'fianlkloy',\n",
              " 'fianlgk',\n",
              " 'figzlly',\n",
              " 'fbanllr',\n",
              " 'fianlleyp',\n",
              " 'fiadllwy',\n",
              " 'pianlwy',\n",
              " 'fqianlmly',\n",
              " 'fafanlly',\n",
              " 'uianllyr',\n",
              " 'fiawllr',\n",
              " 'aianlle',\n",
              " 'fbanwly',\n",
              " 'ftiablly',\n",
              " 'fianlgyo',\n",
              " 'franllyx',\n",
              " 'fonnlly',\n",
              " 'fuanaly',\n",
              " 'faanlfly',\n",
              " 'fialnllya',\n",
              " 'fiarlliy',\n",
              " 'finangly',\n",
              " 'fianllmv',\n",
              " 'wiahnlly',\n",
              " 'ifially',\n",
              " 'fianrdlly',\n",
              " 'fbianllky',\n",
              " 'fiaqnllyx',\n",
              " 'fiacllr',\n",
              " 'fanllj',\n",
              " 'hianlfy',\n",
              " 'hianllu',\n",
              " 'fcanllya',\n",
              " 'kianllf',\n",
              " 'fainily',\n",
              " 'fiznllyd',\n",
              " 'fddanlly',\n",
              " 'fipnlluy',\n",
              " 'fianbllyh',\n",
              " 'fiagnuly',\n",
              " 'flizanlly',\n",
              " 'fsanloly',\n",
              " 'fianllmyx',\n",
              " 'giansly',\n",
              " 'afiallly',\n",
              " 'fiaynlvy',\n",
              " 'ufiganlly',\n",
              " 'fianlmlty',\n",
              " 'fianllgyk',\n",
              " 'fiankbly',\n",
              " 'wyianlly',\n",
              " 'fcianllym',\n",
              " 'firaynlly',\n",
              " 'fainllyh',\n",
              " 'ianlsy',\n",
              " 'fianilsy',\n",
              " 'ofimnlly',\n",
              " 'fiinllyw',\n",
              " 'ftunlly',\n",
              " 'tianoly',\n",
              " 'fivkanlly',\n",
              " 'filaenlly',\n",
              " 'fianelyly',\n",
              " 'fjicanlly',\n",
              " 'fuawnlly',\n",
              " 'fiafnlrly',\n",
              " 'fisjlly',\n",
              " 'kfiyanlly',\n",
              " 'fiaelry',\n",
              " 'fianllck',\n",
              " 'kfiaonlly',\n",
              " 'fianfcly',\n",
              " 'wfianllty',\n",
              " 'fiankldly',\n",
              " 'fyinlly',\n",
              " 'fhianlvly',\n",
              " 'fianlloz',\n",
              " 'tmfianlly',\n",
              " 'fiafllg',\n",
              " 'fvkanlly',\n",
              " 'zianzlly',\n",
              " 'fiynluly',\n",
              " 'fwanlloy',\n",
              " 'ffanllg',\n",
              " 'fiannllm',\n",
              " 'iamlly',\n",
              " 'fignlily',\n",
              " 'fiajnlvly',\n",
              " 'fnvnlly',\n",
              " 'flvnlly',\n",
              " 'fiknply',\n",
              " 'fivally',\n",
              " 'fianhlqy',\n",
              " 'ifianlcly',\n",
              " 'fianldpy',\n",
              " 'fubianlly',\n",
              " 'fianlilyz',\n",
              " 'sflanlly',\n",
              " 'fianlayy',\n",
              " 'fiahfly',\n",
              " 'fhanaly',\n",
              " 'fiagllb',\n",
              " 'fianlvley',\n",
              " 'fiadhnlly',\n",
              " 'diavnlly',\n",
              " 'firanzlly',\n",
              " 'fianulr',\n",
              " 'fmilnlly',\n",
              " 'uizanlly',\n",
              " 'ufiaxnlly',\n",
              " 'faianllyn',\n",
              " 'ftianlkly',\n",
              " 'fhianoly',\n",
              " 'infanlly',\n",
              " 'fianlatly',\n",
              " 'fiqanllw',\n",
              " 'fiamllz',\n",
              " 'fiaknllay',\n",
              " 'fiatlyl',\n",
              " 'dfianllly',\n",
              " 'fiarnbly',\n",
              " 'fiinllyu',\n",
              " 'fiavnllky',\n",
              " 'fianwllyr',\n",
              " 'fianllylb',\n",
              " 'mfianlbly',\n",
              " 'xfiaklly',\n",
              " 'fianlslyx',\n",
              " 'fiisanlly',\n",
              " 'zianflly',\n",
              " 'fhamnlly',\n",
              " 'fizanply',\n",
              " 'ffajlly',\n",
              " 'friranlly',\n",
              " 'fliyanlly',\n",
              " 'fiyanljly',\n",
              " 'fiadnllf',\n",
              " 'fiacnlzy',\n",
              " 'fianollyi',\n",
              " 'viazlly',\n",
              " 'fianyllyo',\n",
              " 'fiajvly',\n",
              " 'fliannly',\n",
              " 'fianrllry',\n",
              " 'fianlpyw',\n",
              " 'ffalnlly',\n",
              " 'fbanlln',\n",
              " 'fiaplily',\n",
              " 'friaplly',\n",
              " 'fiancoly',\n",
              " 'fsiaally',\n",
              " 'firanllby',\n",
              " 'fianlglzy',\n",
              " 'rianllky',\n",
              " 'fianolily',\n",
              " 'fianjllyc',\n",
              " 'fianhllry',\n",
              " 'fianjllyv',\n",
              " 'fiaonlxly',\n",
              " 'miinlly',\n",
              " 'fkvnlly',\n",
              " 'fiaxnhly',\n",
              " 'fiahnlily',\n",
              " 'emanlly',\n",
              " 'hfianllsy',\n",
              " 'ffianllyb',\n",
              " 'fhiranlly',\n",
              " 'nfianlay',\n",
              " 'fianfllw',\n",
              " 'fjhanlly',\n",
              " 'fxanluy',\n",
              " 'yfianldy',\n",
              " 'fianlxls',\n",
              " 'fcanlljy',\n",
              " 'friadlly',\n",
              " 'fianglyi',\n",
              " 'frivanlly',\n",
              " 'fianqxly',\n",
              " 'foianllsy',\n",
              " 'uiajnlly',\n",
              " 'pianllyd',\n",
              " 'ftivnlly',\n",
              " 'fianlsyv',\n",
              " 'fiankvlly',\n",
              " 'fiazllby',\n",
              " 'jfivanlly',\n",
              " 'dfianvly',\n",
              " 'mianlwy',\n",
              " 'fiuanuly',\n",
              " 'fiuslly',\n",
              " 'fiayinlly',\n",
              " 'zfiannly',\n",
              " 'xianvly',\n",
              " 'fbianluy',\n",
              " 'fitanllby',\n",
              " 'giawlly',\n",
              " 'fiznyly',\n",
              " 'wiganlly',\n",
              " 'laanlly',\n",
              " 'fianllyow',\n",
              " 'fauanlly',\n",
              " 'fiyazlly',\n",
              " 'qianltly',\n",
              " 'fhianjly',\n",
              " 'fivmnlly',\n",
              " 'feiantly',\n",
              " 'iianllfy',\n",
              " 'fimanlley',\n",
              " 'fianrgy',\n",
              " 'frimanlly',\n",
              " 'fhanley',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get correct words from above set\n",
        "known(edits1(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIa_shVF9HEf",
        "outputId": "0a738ea1-e026-422b-c720-8b3d94488fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'finally'}"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two edit distances from input word\n",
        "edits2(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ddbLaC9Io5",
        "outputId": "66510bb6-a91c-4ca2-da1b-bc30ce84d858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fniianlly',\n",
              " 'rkianlly',\n",
              " 'fianllem',\n",
              " 'efipnlly',\n",
              " 'fihanally',\n",
              " 'bfianlxy',\n",
              " 'fdanllfy',\n",
              " 'fiantllym',\n",
              " 'ficanlfy',\n",
              " 'hfianlldy',\n",
              " 'fibanlhy',\n",
              " 'fiatolly',\n",
              " 'yiaenlly',\n",
              " 'qiapnlly',\n",
              " 'fionxly',\n",
              " 'fiarlgly',\n",
              " 'fianllqyr',\n",
              " 'feuanlly',\n",
              " 'faiatlly',\n",
              " 'fyiaanlly',\n",
              " 'fiamnlty',\n",
              " 'jfiamnlly',\n",
              " 'finanlxy',\n",
              " 'abianlly',\n",
              " 'fiandllm',\n",
              " 'bxfianlly',\n",
              " 'fyaqnlly',\n",
              " 'fwianllty',\n",
              " 'fianljlyc',\n",
              " 'fianlfyq',\n",
              " 'fianfmy',\n",
              " 'fijnllwy',\n",
              " 'fitanvlly',\n",
              " 'fianzllyq',\n",
              " 'ianlley',\n",
              " 'fianklyk',\n",
              " 'fibanlbly',\n",
              " 'fiuanllyw',\n",
              " 'fixnllb',\n",
              " 'fwiandly',\n",
              " 'fianlggy',\n",
              " 'fianolx',\n",
              " 'fiqnlcly',\n",
              " 'fianulily',\n",
              " 'bficnlly',\n",
              " 'vfianllyh',\n",
              " 'fianldlzy',\n",
              " 'fcianlfly',\n",
              " 'dfianlley',\n",
              " 'fiabllyl',\n",
              " 'cficnlly',\n",
              " 'fvinnlly',\n",
              " 'fxianllw',\n",
              " 'fianlkv',\n",
              " 'fqianlfly',\n",
              " 'fionllq',\n",
              " 'fiamll',\n",
              " 'fiaxnllly',\n",
              " 'fianulyf',\n",
              " 'fianllwc',\n",
              " 'hianllyn',\n",
              " 'fiayjly',\n",
              " 'fiavnldy',\n",
              " 'ofiannly',\n",
              " 'fiuanllyr',\n",
              " 'fianldlye',\n",
              " 'fianolc',\n",
              " 'fhianllyh',\n",
              " 'fianglyc',\n",
              " 'filanltly',\n",
              " 'fiqnllw',\n",
              " 'finnllya',\n",
              " 'fiaullyf',\n",
              " 'fuianllvy',\n",
              " 'fiadnhly',\n",
              " 'fiamklly',\n",
              " 'fianlzlny',\n",
              " 'fiagylly',\n",
              " 'fiqajlly',\n",
              " 'vficanlly',\n",
              " 'fianillay',\n",
              " 'fianlayb',\n",
              " 'fwiankly',\n",
              " 'fiafnllmy',\n",
              " 'miaolly',\n",
              " 'fiangzly',\n",
              " 'vficnlly',\n",
              " 'fianlluay',\n",
              " 'fiaatly',\n",
              " 'fianallyv',\n",
              " 'fuunlly',\n",
              " 'fvianlkly',\n",
              " 'rixanlly',\n",
              " 'fveianlly',\n",
              " 'nianlle',\n",
              " 'fiaenljy',\n",
              " 'jilnlly',\n",
              " 'fkafnlly',\n",
              " 'fianzlliy',\n",
              " 'fwanllu',\n",
              " 'rianlln',\n",
              " 'fcanklly',\n",
              " 'didanlly',\n",
              " 'tfianllyx',\n",
              " 'fpanvlly',\n",
              " 'fbanlely',\n",
              " 'fianlmlu',\n",
              " 'wfianllye',\n",
              " 'fpanllwy',\n",
              " 'fianllcyb',\n",
              " 'fiaggnlly',\n",
              " 'tfiankly',\n",
              " 'fialhlly',\n",
              " 'fianljy',\n",
              " 'bijnlly',\n",
              " 'fiawnloly',\n",
              " 'flianllyx',\n",
              " 'fioanxlly',\n",
              " 'fodnlly',\n",
              " 'fienily',\n",
              " 'ianllyi',\n",
              " 'fianlxy',\n",
              " 'jfianlxly',\n",
              " 'fiavlwy',\n",
              " 'fqiacnlly',\n",
              " 'fianhllcy',\n",
              " 'fiantllyg',\n",
              " 'fianltd',\n",
              " 'fziaglly',\n",
              " 'gianlxy',\n",
              " 'fmanxly',\n",
              " 'fipannlly',\n",
              " 'fiazllyq',\n",
              " 'fiahnlbly',\n",
              " 'fiaxnkly',\n",
              " 'fianlgvly',\n",
              " 'tsianlly',\n",
              " 'fzianlxy',\n",
              " 'fhfanlly',\n",
              " 'fianlildy',\n",
              " 'fhiallly',\n",
              " 'fwianlloy',\n",
              " 'cianljy',\n",
              " 'fnianlny',\n",
              " 'sfianllm',\n",
              " 'fioanlwy',\n",
              " 'fianlljly',\n",
              " 'fikanllyv',\n",
              " 'fidqlly',\n",
              " 'ifianlli',\n",
              " 'fiasnllby',\n",
              " 'fianblaly',\n",
              " 'fisnlli',\n",
              " 'fiuaknlly',\n",
              " 'fiwnoly',\n",
              " 'fianlelhy',\n",
              " 'fcanslly',\n",
              " 'fiamlyl',\n",
              " 'fiankllwy',\n",
              " 'fianlljg',\n",
              " 'firanllay',\n",
              " 'fuianllfy',\n",
              " 'fiandlll',\n",
              " 'cfiafnlly',\n",
              " 'fianvlfly',\n",
              " 'fimnllyy',\n",
              " 'ffianloy',\n",
              " 'qfianlluy',\n",
              " 'wianlley',\n",
              " 'fiaollvy',\n",
              " 'fifanllye',\n",
              " 'filanlxly',\n",
              " 'piannlly',\n",
              " 'dfinanlly',\n",
              " 'fipanlwly',\n",
              " 'ofiaqlly',\n",
              " 'fimxlly',\n",
              " 'firnmlly',\n",
              " 'sfianllyl',\n",
              " 'feaplly',\n",
              " 'fianwllyy',\n",
              " 'fipnluy',\n",
              " 'fianxlyq',\n",
              " 'filanllly',\n",
              " 'fianxllyf',\n",
              " 'siannlly',\n",
              " 'mfiaxlly',\n",
              " 'fjarnlly',\n",
              " 'cfianlrly',\n",
              " 'lianlily',\n",
              " 'fianrlty',\n",
              " 'fianlnld',\n",
              " 'fiailuy',\n",
              " 'filaanlly',\n",
              " 'fihnlla',\n",
              " 'fianclhly',\n",
              " 'fpanluly',\n",
              " 'idfanlly',\n",
              " 'fvzianlly',\n",
              " 'fiaqnlwly',\n",
              " 'bfianxly',\n",
              " 'ufranlly',\n",
              " 'faiaxnlly',\n",
              " 'ofianflly',\n",
              " 'fianrlh',\n",
              " 'fianllx',\n",
              " 'fqtianlly',\n",
              " 'fiarnlcy',\n",
              " 'fkansly',\n",
              " 'fianlqv',\n",
              " 'fianlblny',\n",
              " 'fiadngly',\n",
              " 'fisanll',\n",
              " 'fiknllsy',\n",
              " 'fianljo',\n",
              " 'feianxly',\n",
              " 'fjanully',\n",
              " 'fiqnrlly',\n",
              " 'efinlly',\n",
              " 'ficanlxy',\n",
              " 'fianlkyc',\n",
              " 'pfjanlly',\n",
              " 'tiinlly',\n",
              " 'afhanlly',\n",
              " 'fiavjly',\n",
              " 'zfianaly',\n",
              " 'frzianlly',\n",
              " 'puianlly',\n",
              " 'fienlgly',\n",
              " 'xfiavlly',\n",
              " 'miantlly',\n",
              " 'cianlwly',\n",
              " 'fialnaly',\n",
              " 'fiasnllm',\n",
              " 'finxally',\n",
              " 'fianlmgly',\n",
              " 'fiafnllny',\n",
              " 'fianmay',\n",
              " 'fifnllz',\n",
              " 'fuicanlly',\n",
              " 'filanwlly',\n",
              " 'fvanlliy',\n",
              " 'ufianlloy',\n",
              " 'fiianllvy',\n",
              " 'fiwoanlly',\n",
              " 'finnllyf',\n",
              " 'fdanlcly',\n",
              " 'kfikanlly',\n",
              " 'kfianflly',\n",
              " 'fianfltly',\n",
              " 'fiwaplly',\n",
              " 'fianfyy',\n",
              " 'fianjlljy',\n",
              " 'fiatnzlly',\n",
              " 'fiabldly',\n",
              " 'mianloy',\n",
              " 'fienlls',\n",
              " 'fiakknlly',\n",
              " 'fiahanlly',\n",
              " 'gfianlld',\n",
              " 'vzfianlly',\n",
              " 'dfilnlly',\n",
              " 'fitablly',\n",
              " 'pianllh',\n",
              " 'fgannly',\n",
              " 'vipnlly',\n",
              " 'fizanbly',\n",
              " 'flanlyl',\n",
              " 'tfiadnlly',\n",
              " 'fzianlny',\n",
              " 'fximanlly',\n",
              " 'niyanlly',\n",
              " 'iiatlly',\n",
              " 'nfhianlly',\n",
              " 'pfianlty',\n",
              " 'fianllykg',\n",
              " 'fwianilly',\n",
              " 'fivnmlly',\n",
              " 'finallyi',\n",
              " 'fianelyb',\n",
              " 'fianqlk',\n",
              " 'afiarlly',\n",
              " 'fisanlkly',\n",
              " 'hfipnlly',\n",
              " 'filnqlly',\n",
              " 'fgiawnlly',\n",
              " 'tfiaknlly',\n",
              " 'fignzlly',\n",
              " 'fiacnzly',\n",
              " 'fiaslply',\n",
              " 'ffaolly',\n",
              " 'fkianlply',\n",
              " 'fiianlkly',\n",
              " 'fbaznlly',\n",
              " 'fianlxqy',\n",
              " 'fiaquly',\n",
              " 'fsianllqy',\n",
              " 'fibanilly',\n",
              " 'flivnlly',\n",
              " 'foanllye',\n",
              " 'fianllyew',\n",
              " 'fsafnlly',\n",
              " 'vfianlny',\n",
              " 'fpianlyy',\n",
              " 'kfiahnlly',\n",
              " 'fianzlf',\n",
              " 'fianlltc',\n",
              " 'fianlwqly',\n",
              " 'fianllmyk',\n",
              " 'fianglnly',\n",
              " 'fiafnlnly',\n",
              " 'fiamllry',\n",
              " 'mfiajnlly',\n",
              " 'firaqnlly',\n",
              " 'fnianllyw',\n",
              " 'yianlyl',\n",
              " 'fianxlh',\n",
              " 'fianjllf',\n",
              " 'dfianily',\n",
              " 'fianyhlly',\n",
              " 'flablly',\n",
              " 'fiarglly',\n",
              " 'kfianaly',\n",
              " 'bfiainlly',\n",
              " 'tfianzly',\n",
              " 'oianlaly',\n",
              " 'qianlli',\n",
              " 'fianzlle',\n",
              " 'kianllk',\n",
              " 'nfianlily',\n",
              " 'fianllwyy',\n",
              " 'finalty',\n",
              " 'falianlly',\n",
              " 'uianllym',\n",
              " 'faianllx',\n",
              " 'fianclsy',\n",
              " 'bianwly',\n",
              " 'filnlhy',\n",
              " 'fkanlcly',\n",
              " 'ufianslly',\n",
              " 'fcanily',\n",
              " 'fyianlljy',\n",
              " 'mfiablly',\n",
              " 'fkirnlly',\n",
              " 'flannlly',\n",
              " 'fcianlld',\n",
              " 'dfianldy',\n",
              " 'fionlay',\n",
              " 'kfianllvy',\n",
              " 'fioanllp',\n",
              " 'fianakly',\n",
              " 'vianlbly',\n",
              " 'ffiaylly',\n",
              " 'ianllvy',\n",
              " 'gfianlcly',\n",
              " 'fiadnllw',\n",
              " 'fqianljly',\n",
              " 'hianlaly',\n",
              " 'fignwlly',\n",
              " 'fianllrk',\n",
              " 'fianllvyo',\n",
              " 'fwanlls',\n",
              " 'fioslly',\n",
              " 'fvianmlly',\n",
              " 'fianlxuy',\n",
              " 'fwsanlly',\n",
              " 'ciahnlly',\n",
              " 'finlgy',\n",
              " 'fiaiily',\n",
              " 'kiqnlly',\n",
              " 'fwaynlly',\n",
              " 'ifavnlly',\n",
              " 'fitanllry',\n",
              " 'xiasnlly',\n",
              " 'fzanllny',\n",
              " 'efbanlly',\n",
              " 'mfilanlly',\n",
              " 'filadnlly',\n",
              " 'fiynllyy',\n",
              " 'fiarloy',\n",
              " 'fiafqly',\n",
              " 'fignlaly',\n",
              " 'fianlefly',\n",
              " 'fiatnllf',\n",
              " 'fiakllyq',\n",
              " 'fiadnllj',\n",
              " 'jfianly',\n",
              " 'lfiadlly',\n",
              " 'gfiaally',\n",
              " 'vfianlyy',\n",
              " 'fiasxlly',\n",
              " 'fiahlrly',\n",
              " 'fianldlq',\n",
              " 'fiagnglly',\n",
              " 'ftianllf',\n",
              " 'fkiawlly',\n",
              " 'fidnlyl',\n",
              " 'fpianrlly',\n",
              " 'facianlly',\n",
              " 'fiqanlky',\n",
              " 'fiabnllp',\n",
              " 'ltanlly',\n",
              " 'ofdianlly',\n",
              " 'fiinrly',\n",
              " 'fiarlsy',\n",
              " 'fianlnljy',\n",
              " 'fiagllyh',\n",
              " 'fianzlhly',\n",
              " 'fianllmyg',\n",
              " 'hiaynlly',\n",
              " 'fianlklyx',\n",
              " 'tianllv',\n",
              " 'fijanjlly',\n",
              " 'rfianlty',\n",
              " 'iianmly',\n",
              " 'fiqalnly',\n",
              " 'pfiadnlly',\n",
              " 'xianllyd',\n",
              " 'fiandllk',\n",
              " 'fiandlyc',\n",
              " 'qfianlky',\n",
              " 'sfianlfy',\n",
              " 'finanvlly',\n",
              " 'fivdnlly',\n",
              " 'xibanlly',\n",
              " 'fitanily',\n",
              " 'figantly',\n",
              " 'fiajnlly',\n",
              " 'fianhllyy',\n",
              " 'fvianslly',\n",
              " 'fpiwanlly',\n",
              " 'fianlwlyr',\n",
              " 'fianlolw',\n",
              " 'ftanlyy',\n",
              " 'foiaally',\n",
              " 'fianldp',\n",
              " 'fiaqlld',\n",
              " 'fiqanelly',\n",
              " 'fximnlly',\n",
              " 'fmanluy',\n",
              " 'fiapnilly',\n",
              " 'fianljlxy',\n",
              " 'ghianlly',\n",
              " 'sfvianlly',\n",
              " 'fimnllyx',\n",
              " 'sianllwy',\n",
              " 'hianclly',\n",
              " 'fnianllyq',\n",
              " 'kianllys',\n",
              " 'fianslmly',\n",
              " 'fhanll',\n",
              " 'fianllcye',\n",
              " 'fijanloly',\n",
              " 'nfaanlly',\n",
              " 'fianlun',\n",
              " 'fianxlvy',\n",
              " 'fiafnuly',\n",
              " 'faianllly',\n",
              " 'fianlclb',\n",
              " 'fijanluly',\n",
              " 'faaonlly',\n",
              " 'fipnllwy',\n",
              " 'wfianolly',\n",
              " 'fiantlzy',\n",
              " 'fqaylly',\n",
              " 'fianllxmy',\n",
              " 'fignllyq',\n",
              " 'rgianlly',\n",
              " 'fnanoly',\n",
              " 'fiacrlly',\n",
              " 'fianmllyu',\n",
              " 'fianllyfv',\n",
              " 'pfianly',\n",
              " 'lianully',\n",
              " 'figanbly',\n",
              " 'yiaelly',\n",
              " 'tfianllyd',\n",
              " 'qlfianlly',\n",
              " 'fiabnluly',\n",
              " 'fiwaully',\n",
              " 'fisaflly',\n",
              " 'fimnllr',\n",
              " 'fipnloy',\n",
              " 'fiidanlly',\n",
              " 'faanlly',\n",
              " 'fianjvy',\n",
              " 'gfiagnlly',\n",
              " 'fiaanlzly',\n",
              " 'dianllyj',\n",
              " 'fimnlpy',\n",
              " 'fjiajnlly',\n",
              " 'fianlklyh',\n",
              " 'fiwnclly',\n",
              " 'finllw',\n",
              " 'fkiaknlly',\n",
              " 'fjianlwy',\n",
              " 'fianjllyf',\n",
              " 'feianmly',\n",
              " 'fxanllc',\n",
              " 'ceianlly',\n",
              " 'fianltyw',\n",
              " 'fieganlly',\n",
              " 'ftanllj',\n",
              " 'gfienlly',\n",
              " 'fiyanllry',\n",
              " 'fiazll',\n",
              " 'lianllay',\n",
              " 'jtanlly',\n",
              " 'fiknoly',\n",
              " 'fidanllky',\n",
              " 'yfianlely',\n",
              " 'fianbllyl',\n",
              " 'fianxlv',\n",
              " 'fianngy',\n",
              " 'fianlwb',\n",
              " 'fiainflly',\n",
              " 'fiyplly',\n",
              " 'fianllaye',\n",
              " 'zfiwnlly',\n",
              " 'fiqanllvy',\n",
              " 'fivanlyly',\n",
              " 'fiazlluy',\n",
              " 'fmianlly',\n",
              " 'fiarxnlly',\n",
              " 'fyiaqlly',\n",
              " 'iirnlly',\n",
              " 'fiunllay',\n",
              " 'fianlzlry',\n",
              " 'fianavlly',\n",
              " 'dimanlly',\n",
              " 'xfiarlly',\n",
              " 'gianlsy',\n",
              " 'fianmzy',\n",
              " 'fmxanlly',\n",
              " 'fitnllym',\n",
              " 'ufianlely',\n",
              " 'lfianllsy',\n",
              " 'fiavnlzy',\n",
              " 'fipnltly',\n",
              " 'zianhly',\n",
              " 'fsianllz',\n",
              " 'fsanllyh',\n",
              " 'fianllvvy',\n",
              " 'fiactly',\n",
              " 'fianymly',\n",
              " 'foonlly',\n",
              " 'yfiannly',\n",
              " 'tpfianlly',\n",
              " 'fiankully',\n",
              " 'qiannlly',\n",
              " 'fihnzlly',\n",
              " 'fixavnlly',\n",
              " 'foianllyu',\n",
              " 'fianalvly',\n",
              " 'fianchly',\n",
              " 'fianlmuly',\n",
              " 'pianilly',\n",
              " 'fiasngly',\n",
              " 'siaglly',\n",
              " 'fikanllp',\n",
              " 'fiamunlly',\n",
              " 'firanlwly',\n",
              " 'ffiaelly',\n",
              " 'fiaqnlty',\n",
              " 'fianlglc',\n",
              " 'fiaztlly',\n",
              " 'fnrianlly',\n",
              " 'fieanllyr',\n",
              " 'ifianlwy',\n",
              " 'vfianlldy',\n",
              " 'fyqnlly',\n",
              " 'fiaullyo',\n",
              " 'xfianlrly',\n",
              " 'fwianllyr',\n",
              " 'fionluly',\n",
              " 'rfiajlly',\n",
              " 'oiaqlly',\n",
              " 'gfianclly',\n",
              " 'vfianllq',\n",
              " 'fihanllxy',\n",
              " 'fsanyly',\n",
              " 'fiaznllz',\n",
              " 'fianxlyy',\n",
              " 'tianlqy',\n",
              " 'fianllhyx',\n",
              " 'fiankmly',\n",
              " 'bafianlly',\n",
              " 'fmanfly',\n",
              " 'ffanlloy',\n",
              " 'foagnlly',\n",
              " 'ufianlwly',\n",
              " 'faanllyl',\n",
              " 'fiapelly',\n",
              " 'fianllwi',\n",
              " 'fiatrly',\n",
              " 'fiakllyv',\n",
              " 'fiafllcy',\n",
              " 'hivanlly',\n",
              " 'jianlsy',\n",
              " 'fiaulldy',\n",
              " 'fdanbly',\n",
              " 'fidanrlly',\n",
              " 'fqanllly',\n",
              " 'fianljlj',\n",
              " 'eianlty',\n",
              " 'ritanlly',\n",
              " 'fiakvnlly',\n",
              " 'fsanslly',\n",
              " 'gipnlly',\n",
              " 'fsanllj',\n",
              " 'fipxlly',\n",
              " 'frianllty',\n",
              " 'fifnlle',\n",
              " 'fiacnlby',\n",
              " 'feiaenlly',\n",
              " 'cxianlly',\n",
              " 'fiahllyc',\n",
              " 'ftanjlly',\n",
              " 'fijanlsly',\n",
              " 'fkeanlly',\n",
              " 'finoly',\n",
              " 'fianallt',\n",
              " 'fgicnlly',\n",
              " 'fzanluly',\n",
              " 'fitanllyf',\n",
              " 'fuanllwy',\n",
              " 'ehfianlly',\n",
              " 'fianlsyly',\n",
              " 'fiancrly',\n",
              " 'vixnlly',\n",
              " 'fianltyc',\n",
              " 'firtlly',\n",
              " 'fianllq',\n",
              " 'fxanlry',\n",
              " 'fienlln',\n",
              " 'fuiatlly',\n",
              " 'wikanlly',\n",
              " 'kianllty',\n",
              " 'fianjlyk',\n",
              " 'fiahnllty',\n",
              " 'fjafnlly',\n",
              " 'fmianljly',\n",
              " 'ziaflly',\n",
              " 'fsyianlly',\n",
              " 'fqianaly',\n",
              " 'fiallaly',\n",
              " 'pfiawnlly',\n",
              " 'fisanljly',\n",
              " 'mfbianlly',\n",
              " 'fioanllyq',\n",
              " 'fianillyv',\n",
              " 'fiknqly',\n",
              " 'hfianllj',\n",
              " 'cpianlly',\n",
              " 'fiantlyj',\n",
              " 'fijnlmy',\n",
              " 'fixnlvly',\n",
              " 'lially',\n",
              " 'fianrjly',\n",
              " 'fwianllzy',\n",
              " 'tiwanlly',\n",
              " 'tfipnlly',\n",
              " 'aianwlly',\n",
              " 'fianwey',\n",
              " 'tiaqnlly',\n",
              " 'bfiadnlly',\n",
              " 'fcnally',\n",
              " 'kfiatnlly',\n",
              " 'fianccly',\n",
              " 'figanllo',\n",
              " 'fiaonllxy',\n",
              " 'fismanlly',\n",
              " 'fianlzlt',\n",
              " 'fdatlly',\n",
              " 'ftanllhy',\n",
              " 'fianmllya',\n",
              " 'fiaznllyo',\n",
              " 'biankly',\n",
              " 'fiafnllh',\n",
              " 'fikkanlly',\n",
              " 'fitqnlly',\n",
              " 'yianllzy',\n",
              " 'fiiklly',\n",
              " 'ftianly',\n",
              " 'iuanlly',\n",
              " 'fraynlly',\n",
              " 'foijnlly',\n",
              " 'fiandlay',\n",
              " 'uianllq',\n",
              " 'fianzlgy',\n",
              " 'fciajlly',\n",
              " 'fianllmsy',\n",
              " 'fianllghy',\n",
              " 'tfiaunlly',\n",
              " 'tfianwly',\n",
              " 'fiasnllx',\n",
              " 'fifanllmy',\n",
              " 'fianlely',\n",
              " 'fisanoly',\n",
              " 'fitaslly',\n",
              " 'fiaenllyc',\n",
              " 'fgianlqly',\n",
              " 'hfianllyq',\n",
              " 'faidnlly',\n",
              " 'fianhlz',\n",
              " 'fiuaally',\n",
              " 'fiahnley',\n",
              " 'diaflly',\n",
              " 'fmwanlly',\n",
              " 'xfnanlly',\n",
              " 'fiznllay',\n",
              " 'fjaunlly',\n",
              " 'fianllxo',\n",
              " 'uianjly',\n",
              " 'fianlcm',\n",
              " 'fnanllx',\n",
              " 'fmiarnlly',\n",
              " 'fvlanlly',\n",
              " 'aianltly',\n",
              " 'fizanlldy',\n",
              " 'fiaolgly',\n",
              " 'fiunlky',\n",
              " 'franqly',\n",
              " 'gianllq',\n",
              " 'fiaulby',\n",
              " 'fianlnnly',\n",
              " 'fianbllyc',\n",
              " 'fianlpxy',\n",
              " 'filnflly',\n",
              " 'fianilily',\n",
              " 'fhianlhly',\n",
              " 'fijajlly',\n",
              " 'fienllfy',\n",
              " 'franlls',\n",
              " 'iianllby',\n",
              " 'wiaynlly',\n",
              " 'fianblxly',\n",
              " 'fianliloy',\n",
              " 'fdianljly',\n",
              " 'oimnlly',\n",
              " 'fiainllyx',\n",
              " 'ffanlily',\n",
              " 'fclianlly',\n",
              " 'fianvlluy',\n",
              " 'fiavtnlly',\n",
              " 'fxiagnlly',\n",
              " 'efganlly',\n",
              " 'fianvllvy',\n",
              " 'qixnlly',\n",
              " 'tianelly',\n",
              " 'fviantly',\n",
              " 'fiyanlqy',\n",
              " 'fikanllyq',\n",
              " 'fihanlrly',\n",
              " 'fgianllyo',\n",
              " 'mzianlly',\n",
              " 'fimnllyl',\n",
              " 'ziatlly',\n",
              " 'fiinllwy',\n",
              " 'fizanlyl',\n",
              " 'fiislly',\n",
              " 'fiaoolly',\n",
              " 'fiexanlly',\n",
              " 'fnanlli',\n",
              " 'fialey',\n",
              " 'fipanhly',\n",
              " 'fknnlly',\n",
              " 'fdanllj',\n",
              " 'fiahllzy',\n",
              " 'fiatllsy',\n",
              " 'flvianlly',\n",
              " 'fiutlly',\n",
              " 'spfianlly',\n",
              " 'fiavlliy',\n",
              " 'fpiadnlly',\n",
              " 'tiajnlly',\n",
              " 'fiacnllby',\n",
              " 'fboanlly',\n",
              " 'fianhlyv',\n",
              " 'fqanlyy',\n",
              " 'fianbllw',\n",
              " 'fbranlly',\n",
              " 'fxiranlly',\n",
              " 'franllyv',\n",
              " 'fianidy',\n",
              " 'fianlluyt',\n",
              " 'fianlimy',\n",
              " 'fianzllo',\n",
              " 'fiznlky',\n",
              " 'fianlkloy',\n",
              " 'fianlgk',\n",
              " 'figzlly',\n",
              " 'fbanllr',\n",
              " 'fianlleyp',\n",
              " 'fiadllwy',\n",
              " 'pianlwy',\n",
              " 'fqianlmly',\n",
              " 'fafanlly',\n",
              " 'uianllyr',\n",
              " 'fiawllr',\n",
              " 'aianlle',\n",
              " 'fbanwly',\n",
              " 'ftiablly',\n",
              " 'fianlgyo',\n",
              " 'franllyx',\n",
              " 'fonnlly',\n",
              " 'fuanaly',\n",
              " 'faanlfly',\n",
              " 'fialnllya',\n",
              " 'fiarlliy',\n",
              " 'finangly',\n",
              " 'fianllmv',\n",
              " 'wiahnlly',\n",
              " 'ifially',\n",
              " 'fianrdlly',\n",
              " 'fbianllky',\n",
              " 'fiaqnllyx',\n",
              " 'fiacllr',\n",
              " 'fanllj',\n",
              " 'hianlfy',\n",
              " 'hianllu',\n",
              " 'fcanllya',\n",
              " 'kianllf',\n",
              " 'fainily',\n",
              " 'fiznllyd',\n",
              " 'fddanlly',\n",
              " 'fipnlluy',\n",
              " 'fianbllyh',\n",
              " 'fiagnuly',\n",
              " 'flizanlly',\n",
              " 'fsanloly',\n",
              " 'fianllmyx',\n",
              " 'giansly',\n",
              " 'afiallly',\n",
              " 'fiaynlvy',\n",
              " 'ufiganlly',\n",
              " 'fianlmlty',\n",
              " 'fianllgyk',\n",
              " 'fiankbly',\n",
              " 'wyianlly',\n",
              " 'fcianllym',\n",
              " 'firaynlly',\n",
              " 'fainllyh',\n",
              " 'ianlsy',\n",
              " 'fianilsy',\n",
              " 'ofimnlly',\n",
              " 'fiinllyw',\n",
              " 'ftunlly',\n",
              " 'tianoly',\n",
              " 'fivkanlly',\n",
              " 'filaenlly',\n",
              " 'fianelyly',\n",
              " 'fjicanlly',\n",
              " 'fuawnlly',\n",
              " 'fiafnlrly',\n",
              " 'fisjlly',\n",
              " 'kfiyanlly',\n",
              " 'fiaelry',\n",
              " 'fianllck',\n",
              " 'kfiaonlly',\n",
              " 'fianfcly',\n",
              " 'wfianllty',\n",
              " 'fiankldly',\n",
              " 'fyinlly',\n",
              " 'fhianlvly',\n",
              " 'fianlloz',\n",
              " 'tmfianlly',\n",
              " 'fiafllg',\n",
              " 'fvkanlly',\n",
              " 'zianzlly',\n",
              " 'fiynluly',\n",
              " 'fwanlloy',\n",
              " 'ffanllg',\n",
              " 'fiannllm',\n",
              " 'iamlly',\n",
              " 'fignlily',\n",
              " 'fiajnlvly',\n",
              " 'fnvnlly',\n",
              " 'flvnlly',\n",
              " 'fiknply',\n",
              " 'fivally',\n",
              " 'fianhlqy',\n",
              " 'ifianlcly',\n",
              " 'fianldpy',\n",
              " 'fubianlly',\n",
              " 'fianlilyz',\n",
              " 'sflanlly',\n",
              " 'fianlayy',\n",
              " 'fiahfly',\n",
              " 'fhanaly',\n",
              " 'fiagllb',\n",
              " 'fianlvley',\n",
              " 'fiadhnlly',\n",
              " 'diavnlly',\n",
              " 'firanzlly',\n",
              " 'fianulr',\n",
              " 'fmilnlly',\n",
              " 'uizanlly',\n",
              " 'ufiaxnlly',\n",
              " 'faianllyn',\n",
              " 'ftianlkly',\n",
              " 'fhianoly',\n",
              " 'infanlly',\n",
              " 'fianlatly',\n",
              " 'fiqanllw',\n",
              " 'fiamllz',\n",
              " 'fiaknllay',\n",
              " 'fiatlyl',\n",
              " 'dfianllly',\n",
              " 'fiarnbly',\n",
              " 'fiinllyu',\n",
              " 'fiavnllky',\n",
              " 'fianwllyr',\n",
              " 'fianllylb',\n",
              " 'mfianlbly',\n",
              " 'xfiaklly',\n",
              " 'fianlslyx',\n",
              " 'fiisanlly',\n",
              " 'zianflly',\n",
              " 'fhamnlly',\n",
              " 'fizanply',\n",
              " 'ffajlly',\n",
              " 'friranlly',\n",
              " 'fliyanlly',\n",
              " 'fiyanljly',\n",
              " 'fiadnllf',\n",
              " 'fiacnlzy',\n",
              " 'fianollyi',\n",
              " 'viazlly',\n",
              " 'fianyllyo',\n",
              " 'fiajvly',\n",
              " 'fliannly',\n",
              " 'fianrllry',\n",
              " 'fianlpyw',\n",
              " 'ffalnlly',\n",
              " 'fbanlln',\n",
              " 'fiaplily',\n",
              " 'friaplly',\n",
              " 'fiancoly',\n",
              " 'fsiaally',\n",
              " 'firanllby',\n",
              " 'fianlglzy',\n",
              " 'rianllky',\n",
              " 'fianolily',\n",
              " 'fianjllyc',\n",
              " 'fianhllry',\n",
              " 'fianjllyv',\n",
              " 'fiaonlxly',\n",
              " 'miinlly',\n",
              " 'fkvnlly',\n",
              " 'fiaxnhly',\n",
              " 'fiahnlily',\n",
              " 'emanlly',\n",
              " 'hfianllsy',\n",
              " 'ffianllyb',\n",
              " 'fhiranlly',\n",
              " 'nfianlay',\n",
              " 'fianfllw',\n",
              " 'fjhanlly',\n",
              " 'fxanluy',\n",
              " 'yfianldy',\n",
              " 'fianlxls',\n",
              " 'fcanlljy',\n",
              " 'friadlly',\n",
              " 'fianglyi',\n",
              " 'frivanlly',\n",
              " 'fianqxly',\n",
              " 'foianllsy',\n",
              " 'uiajnlly',\n",
              " 'pianllyd',\n",
              " 'ftivnlly',\n",
              " 'fianlsyv',\n",
              " 'fiankvlly',\n",
              " 'fiazllby',\n",
              " 'jfivanlly',\n",
              " 'dfianvly',\n",
              " 'mianlwy',\n",
              " 'fiuanuly',\n",
              " 'fiuslly',\n",
              " 'fiayinlly',\n",
              " 'zfiannly',\n",
              " 'xianvly',\n",
              " 'fbianluy',\n",
              " 'fitanllby',\n",
              " 'giawlly',\n",
              " 'fiznyly',\n",
              " 'wiganlly',\n",
              " 'laanlly',\n",
              " 'fianllyow',\n",
              " 'fauanlly',\n",
              " 'fiyazlly',\n",
              " 'qianltly',\n",
              " 'fhianjly',\n",
              " 'fivmnlly',\n",
              " 'feiantly',\n",
              " 'iianllfy',\n",
              " 'fimanlley',\n",
              " 'fianrgy',\n",
              " 'frimanlly',\n",
              " 'fhanley',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get correct words from above set\n",
        "known(edits2(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAKqwdgI9j_d",
        "outputId": "4edc4a82-21ff-4785-ddd2-b972e75829af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'faintly', 'finally', 'finely', 'frankly'}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = (known(edits0(word)) or\n",
        "              known(edits1(word)) or\n",
        "              known(edits2(word)) or\n",
        "              [word])\n",
        "candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js_myByO9l86",
        "outputId": "6d1786ca-13b4-4207-d9db-19daee9ce3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'finally'}"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(word):\n",
        "    \"\"\"\n",
        "    Get the best correct spelling for the input word\n",
        "    \"\"\"\n",
        "    # Priority is for edit distance 0, then 1, then 2\n",
        "    # else defaults to the input word itself.\n",
        "    candidates = (known(edits0(word)) or\n",
        "                  known(edits1(word)) or\n",
        "                  known(edits2(word)) or\n",
        "                  [word])\n",
        "    return max(candidates, key=WORD_COUNTS.get)"
      ],
      "metadata": {
        "id": "f8Qh3WL_9n6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct('fianlly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4UzYxvnA9p7V",
        "outputId": "f31d28cd-df3c-4ee3-bd35-39ca6cba9379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'finally'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct('FIANLLY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "g2Ajz9gf9r4V",
        "outputId": "13c8c704-fda2-40f3-b66e-b9873131db43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FIANLLY'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_match(match):\n",
        "    \"\"\"\n",
        "    Spell-correct word in match,\n",
        "    and preserve proper upper/lower/title case.\n",
        "    \"\"\"\n",
        "\n",
        "    word = match.group()\n",
        "    def case_of(text):\n",
        "        \"\"\"\n",
        "        Return the case-function appropriate\n",
        "        for text: upper, lower, title, or just str.:\n",
        "            \"\"\"\n",
        "        return (str.upper if text.isupper() else\n",
        "                str.lower if text.islower() else\n",
        "                str.title if text.istitle() else\n",
        "                str)\n",
        "    return case_of(word)(correct(word.lower()))\n",
        "\n",
        "\n",
        "def correct_text_generic(text):\n",
        "    \"\"\"\n",
        "    Correct all the words within a text,\n",
        "    returning the corrected text.\n",
        "    \"\"\"\n",
        "    return re.sub('[a-zA-Z]+', correct_match, text)"
      ],
      "metadata": {
        "id": "lUeRpWIV9t-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_text_generic('fianlly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tU8g4o189wQI",
        "outputId": "80a1fbbf-df65-444a-fa2f-83be003989fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'finally'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_text_generic('FIANLLY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kfqUle8J9yXy",
        "outputId": "b034e437-2ba0-4c95-f259-0187bf809979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FINALLY'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "\n",
        "w = Word('fianlly')\n",
        "w.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PaRVGJLH90LJ",
        "outputId": "80ccb419-5af8-4496-d479-7e7e75afe4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'finally'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.spellcheck()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTIJnUSm916L",
        "outputId": "1ab69578-82a4-4b42-f1b1-e30f1926c8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('finally', 1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Word('flaot')\n",
        "w.spellcheck()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onLQDYkC930Y",
        "outputId": "5ef91051-c808-4228-ce86-9eaf5a4a82ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('flat', 0.85), ('float', 0.15)]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize #"
      ],
      "metadata": {
        "id": "53laEn8yQqzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True,\n",
        "                     text_lemmatization=True, special_char_removal=True,\n",
        "                     stopword_removal=True, remove_digits=True):\n",
        "\n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "        # expand contractions\n",
        "        if contraction_expansion:\n",
        "            doc = contractions.fix(doc)\n",
        "        # lowercase the text\n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove extra newlines\n",
        "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "        # remove special characters and\\or digits\n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them\n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits)\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
        "\n",
        "        normalized_corpus.append(doc)\n",
        "\n",
        "    return normalized_corpus"
      ],
      "metadata": {
        "id": "AKDNnWqm97yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \"\n",
        "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \"\n",
        "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
        "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
        "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
        "               \"which reportedly take up the size of two tennis courts.\")"
      ],
      "metadata": {
        "id": "XtJ-h-rf9-4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{'Original': sample_text,\n",
        " 'Processed': normalize_corpus([sample_text])[0]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOpcKpqA-AtF",
        "outputId": "43150d97-519a-48e5-e64b-0ecb2e05dfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Original': \"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\",\n",
              " 'Processed': 'us unveil world powerful supercomputer beat china us unveil world powerful supercomputer call summit beat previous record holder china sunway taihulight peak performance trillion calculation per second twice fast sunway taihulight capable trillion calculation per second summit server reportedly take size two tennis court'}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    }
  ]
}